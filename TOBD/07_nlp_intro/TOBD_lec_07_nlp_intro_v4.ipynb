{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 7: Введение в обработку текста на естественном языке\n",
    "\n",
    "__Автор: Сергей Вячеславович Макрушин, 2022 г.__\n",
    "\n",
    "e-mail: s-makrushin@yandex.ru \n",
    "\n",
    "V 0.4 23.10.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделы: <a class=\"anchor\" id=\"разделы\"></a>\n",
    "* [Метрики расстояния между строками](#расстояние)\n",
    "    * [Расстояние Левенштейна](#левенштейн)\n",
    "    * [Динамическое программирование](#динамическое)\n",
    "    * [Алгоритм Вагнера - Фишера](#вагнер)    \n",
    "* [Стемминг и лемматизация](#стемминг)\n",
    "    * [Стемминг](#cтемминг)\n",
    "    * [Лемматизация](#лемматизация)\n",
    "* [Стоп-слова](#стоп)    \n",
    "* [Мешок слов](#мешок)\n",
    "* [Векторное представление документа](#векторный-документ)\n",
    "  \n",
    "-\n",
    "\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "﻿<style>\r\n",
       "\r\n",
       "\r\n",
       "b.n {\r\n",
       "    font-weight: normal;        \r\n",
       "}\r\n",
       "\r\n",
       "b.grbg {\r\n",
       "    background-color: #a0a0a0;      \r\n",
       "}\r\n",
       "\r\n",
       "b.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "b.b {    \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "b.g {\r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "// add your CSS styling here\r\n",
       "\r\n",
       "list-style: none;\r\n",
       "\r\n",
       "ul.s {\r\n",
       "//    list-style-type: none;\r\n",
       "    list-style: none;\r\n",
       "//    background-color: #ff0000;  \r\n",
       "//    color: #ffff00;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;\r\n",
       "}\r\n",
       "\r\n",
       "li.t {\r\n",
       "    list-style: none;\r\n",
       "//  padding-left: 1.2em;\r\n",
       "//  text-indent: -1.2em;    \r\n",
       "}\r\n",
       "\r\n",
       "\r\n",
       "*.r {\r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "li.t:before {\r\n",
       "    content: \"\\21D2\";    \r\n",
       "//    content: \"►\";\r\n",
       "//    padding-left: -1.2em;    \r\n",
       "    text-indent: -1.2em;    \r\n",
       "    display: block;\r\n",
       "    float: left;\r\n",
       "    \r\n",
       "    \r\n",
       "//    width: 1.2em;\r\n",
       "//    color: #ff0000;\r\n",
       "}\r\n",
       "\r\n",
       "i.m:before {\r\n",
       "    font-style: normal;    \r\n",
       "    content: \"\\21D2\";  \r\n",
       "}\r\n",
       "i.m {\r\n",
       "    font-style: normal; \r\n",
       "}    \r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "/* em {\r\n",
       "    font-style: normal; \r\n",
       "} */\r\n",
       "\r\n",
       "\r\n",
       "em.bl {\r\n",
       "    font-style: normal;     \r\n",
       "    font-weight: bold;        \r\n",
       "}\r\n",
       "\r\n",
       "/* em.grbg {\r\n",
       "    font-style: normal;         \r\n",
       "    background-color: #a0a0a0;      \r\n",
       "} */\r\n",
       "\r\n",
       "em.cr {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #ff0000;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cb {    \r\n",
       "    font-style: normal;         \r\n",
       "    color: #0000ff;    \r\n",
       "}\r\n",
       "\r\n",
       "em.cg {\r\n",
       "    font-style: normal;         \r\n",
       "    color: #00ff00;    \r\n",
       "}\r\n",
       "\r\n",
       "/*--------------------*/\r\n",
       "\r\n",
       "em.qs {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.qs::before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #ff0000;    \r\n",
       "    content: \"Q:\";  \r\n",
       "}\r\n",
       "\r\n",
       "em.an {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.an:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"A:\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.nt {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.nt:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Note:\";  \r\n",
       "}    \r\n",
       "    \r\n",
       "em.ex {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.ex:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #00ff00;    \r\n",
       "    content: \"Ex:\";  \r\n",
       "} \r\n",
       "    \r\n",
       "em.df {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.df:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"Def:\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.pl {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.pl:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"+\";  \r\n",
       "}    \r\n",
       "\r\n",
       "em.mn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.mn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"-\";  \r\n",
       "}        \r\n",
       "\r\n",
       "em.plmn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.plmn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\00B1\";\\\\\"&plusmn;\";  \r\n",
       "}\r\n",
       "    \r\n",
       "em.hn {\r\n",
       "    font-style: normal; \r\n",
       "}\r\n",
       "\r\n",
       "em.hn:before {\r\n",
       "    font-weight: bold;    \r\n",
       "    color: #0000ff;    \r\n",
       "    content: \"\\21D2\";\\\\\"&rArr;\";  \r\n",
       "}     \r\n",
       "    \r\n",
       "\r\n",
       "#cssTableCenter td, th \r\n",
       "{\r\n",
       "    text-align: center; \r\n",
       "    vertical-align: middle;\r\n",
       "}\r\n",
       "\r\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем стиль для оформления презентации\n",
    "from IPython.display import HTML\n",
    "from urllib.request import urlopen\n",
    "html = urlopen(\"file:./lec_v2.css\")\n",
    "HTML(html.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики расстояния между строками <a class=\"anchor\" id=\"расстояние\"></a>\n",
    "\n",
    "-\n",
    "\n",
    "[к оглавлению](#разделы)\n",
    "\n",
    "\n",
    "* Расстояние Левенштейна\n",
    "* Алгоритм поиска минимального редакционного расстояния Вагнера - Фишера\n",
    "* Задача динамического программирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Метрики расстояния для строк__\n",
    "\n",
    "Часто требуется понять, насколько близкими являются две несовпадающих строки (слова). Это может потребоваться для:\n",
    "* для сравнения тексктов, предложений\n",
    "* поиска ошибок и опечаток в слове\n",
    "* поиска словоформ слова\n",
    "* в других областях (в биоинформатике для сравнения генов, хромосом и белков)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расстояние Левенштейна <a class=\"anchor\" id=\"левенштейн\"></a>\n",
    "\n",
    "-\n",
    "\n",
    "[к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Расстояние Левенштейна__ (редакционное расстояние, дистанция редактирования) - __минимальное__ количество операций необходимых для превращения одной строки в другую. Рассматриваются следующие операции:\n",
    "* вставка одного символа\n",
    "* удаление одного символа \n",
    "* замена одного символа на другим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>         \n",
    "    <img src=\"./img/levinst1.png\" alt=\"Пример выполнения операций вставки, удаления и замены\" style=\"width: 500px;\"/>\n",
    "    <b>Пример выполнения операций вставки, удаления и замены для слова \"intention\"</b>    \n",
    "</center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/levinst2_.png\" alt=\"Пример преобразования слова\" style=\"width: 500px;\"/>\n",
    "    <b>Пример преобразования слова \"intention\" в \"execution\" с помощью операций вставки, удаления и замены</b>\n",
    "</center>\n",
    "\n",
    "\n",
    "В общем случае __стоимость различных операций__ может быть различной. Обычно цена отражает __разную вероятность__ событий и может зависеть от:\n",
    "* вида операции (вставка, удаление, замена) \n",
    "* и/или от участвующих в ней символов\n",
    "\n",
    "\n",
    "Если к списку разрешённых операций добавить __транспозицию__ (два соседних символа меняются местами), получается __расстояние Дамерау - Левенштейна__. \n",
    "* Дамерау показал, что 80 % ошибок при наборе текста человеком являются транспозициями.\n",
    "* Кроме того, это расстояние используется и в биоинформатике. \n",
    "\n",
    "Для поиска расстояния Левинштайна и расстояния Дамерау - Левинштайна __существуют эффективные алгоритм__, требующий $O(MN)$ операций ($M$ и $N$ это длины первой и второй строки соответственно)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Пусть $S_1$ и $S_2$ - две строки (длиной $M$ и $N$ соответственно, здесь и далее считается, что элементы строк нумеруются с первого, как принято в математике) над некоторым алфавитом, тогда расстояние Левенштейна $\\operatorname{d}(S_1,S_2)$ можно подсчитать используя вспомогательную функцию $D(M,N)$, находящую редакционное расстояние для подстрок $S_1[0 .. M]$ и $S_2[0 .. N]$\n",
    "\n",
    "по следующей рекуррентной формуле:\n",
    "\n",
    "$$\\ \\operatorname{d}(S_1, S_2) = \\operatorname{D}(M,N)$$\n",
    "\n",
    "$$\\qquad\\operatorname{D}(i,j) = \\begin{cases}\n",
    "  \\max(i,j) & \\text{ if } \\min(i,j)=0, \\\\\n",
    "  \\min \\begin{cases}\n",
    "          \\operatorname{D}(i-1,j) + 1 \\\\\n",
    "          \\operatorname{D}(i,j-1) + 1 \\\\\n",
    "          \\operatorname{D}(i-1,j-1) + \\operatorname{m}(S_1[i], S_2[j])\n",
    "       \\end{cases} & \\text{ otherwise.}\n",
    "\\end{cases}$$\n",
    "\n",
    "$$\\operatorname{D}(i-1,j) + 1 \\text{, операция удаления (цена: 1, на схеме обозначается как: } \\uparrow) $$\n",
    "$$\\operatorname{D}(i,j-1) + 1 \\text{, операция вставки (цена: 1, на схеме обозначается как: } \\leftarrow)$$\n",
    "$$\\operatorname{D}(i-1,j-1) + \\operatorname{m}(S_1[i], S_2[j]) \\text{, операция замены (цена m, на схеме обозначается как: } \\nwarrow)$$\n",
    "\n",
    "Цена операции замены зависит от заменяемых символов:\n",
    "\n",
    "$$\\operatorname{m}(s_1, s_2) = \\begin{cases}\n",
    "0 \\text{ , if } s_1 = s_2 \\\\\n",
    "2 \\text{ , if } s_1 \\neq s_2 \\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "Очевидно, что для расстояния Левинштайна справедливы следующие утверждения:\n",
    "* $\\operatorname{d}(S_1,S_2) \\geqslant \\bigl| |S_1| - |S_2| \\bigr|$\n",
    "* $\\operatorname{d}(S_1,S_2) \\leqslant \\max\\bigl( |S_1| , |S_2| \\bigr)$\n",
    "* $\\operatorname{d}(S_1,S_2) = 0 \\Leftrightarrow S_1 = S_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Редакционным предписанием__ называется последовательность действий, необходимых для получения второй строки из первой кратчайшим образом. Обычно действия обозначаются так:\n",
    "* `D` (англ. delete) — удалить\n",
    "* `I` (англ. insert) — вставить\n",
    "* `R` (replace) — заменить\n",
    "* `M` (match) — совпадение.\n",
    "\n",
    "По сути редакционное предписание это кратчайшие пути на графе с весами, в котором существует 3 вида ориентированных ребер (D, I, M), а вершинами являются строки (слова). В общем случае для конкретной пары слов может существовать несколько редакционных предписаний (кратчайших путей на графе)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Динамическое программирование <a class=\"anchor\" id=\"динамическое\"></a>\n",
    "\n",
    "-\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Динамическое программирование__ - способ решения сложных задач путём разбиения их на более простые подзадачи. Он применим к *задачам с оптимальной подструктурой*, выглядящим как *набор перекрывающихся подзадач*, сложность которых чуть меньше исходной. В этом случае время вычислений, по сравнению с «наивными» методами, можно значительно сократить.\n",
    "\n",
    "__Идея динамического программирования:__\n",
    "\n",
    "*Оптимальная подструктура* в динамическом программировании означает, что оптимальное решение подзадач меньшего размера может быть использовано для решения исходной задачи. \n",
    "\n",
    "В общем случае мы можем решить задачу, в которой присутствует оптимальная подструктура, проделывая следующие три шага.\n",
    "\n",
    "1. Разбиение задачи на подзадачи меньшего размера.\n",
    "2. Нахождение оптимального решения подзадач рекурсивно, проделывая такой же трехшаговый алгоритм.\n",
    "3. Использование полученного решения подзадач для конструирования решения исходной задачи.\n",
    "\n",
    "Часто многие из рассматриваемых подзадач одинаковы. Подход динамического программирования состоит в том, чтобы *решить каждую подзадачу только один раз*, сократив тем самым количество вычислений. Это особенно полезно в случаях, когда число повторяющихся подзадач экспоненциально велико.\n",
    "\n",
    "* Метод динамического программирования __сверху-вниз__ (top-down approach) - это простое *запоминание результатов решения тех подзадач*, которые могут повторно встретиться в дальнейшем. \n",
    "* Динамическое программирование __снизу-вверх__ (bottom-up approach) включает в себя переформулирование сложной задачи в виде рекурсивной последовательности более простых подзадач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Пример использования динамического программирования__\n",
    "\n",
    "Пример: подсчет факториалов последоватеьности чисел от `0` до `m`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Наивное решение задачи:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_factorial(n):\n",
    "    factorial = 1\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        for i in range (1, n + 1):\n",
    "            factorial = factorial * i\n",
    "        return factorial\n",
    "    \n",
    "def factorial_seq_1(m):\n",
    "    return [iter_factorial(i) for i in range(m+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_factorial(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880, 3628800]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial_seq_1(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "546 µs ± 37.6 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "factorial_seq_1(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Рекурсивное решение задачи:_\n",
    "\n",
    "(Динамическое программирование снизу-вверх)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рекурсивная реализация:\n",
    "\n",
    "def rec_factorial(n):\n",
    "    if n == 0 or n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * rec_factorial(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_factorial(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_factorial_for_seq(n, result):\n",
    "    if n == 0:\n",
    "        result.append(1)\n",
    "    else:\n",
    "        result.append(n * rec_factorial_for_seq(n-1, result))\n",
    "    return result[-1]\n",
    "\n",
    "def factorial_seq_2(m):\n",
    "    res = []\n",
    "    rec_factorial_for_seq(m, res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880, 3628800]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial_seq_2(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 µs ± 2 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "factorial_seq_2(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Рекурсивное решение задачи:_\n",
    "\n",
    "(Динамическое программирование свверху-вниз, на основе кеширования)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1024)\n",
    "def rec_factorial_cache(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * rec_factorial(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_factorial_cache(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial_seq_3(m):\n",
    "    return [rec_factorial_cache(i) for i in range(m+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 6, 24, 120, 720, 5040, 40320, 362880, 3628800]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial_seq_3(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.2 µs ± 1.53 µs per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "factorial_seq_3(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Алгоритм Вагнера - Фишера <a class=\"anchor\" id=\"вагнер\"></a>\n",
    "\n",
    "-\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя рекурсивное определение расстояния Левинштайна $\\operatorname{D}(i,j)$ через расстояния для слов меньшей длины: $\\operatorname{D}(i-1,j) \\text{ , } \\operatorname{D}(i,j-1) \\text{ , } \\operatorname{D}(i-1,j-1)$ мы применим принцип динамического программирования снизу-вверх, комбинируя решения подзадач, для решения более сложной задачи. \n",
    "\n",
    "1. Для получения базового решения когда конечная строка длины 0 или исходная строка длинны 0:\n",
    "    * $\\operatorname{D}(i, 0) = i $ - используется $i$ операций удаления (на схеме операция удаления обозначается, как: \"$\\uparrow$\")\n",
    "    * $\\operatorname{D}(0, j) = j$ - используется $j$ операций вставки (на схеме операция вставки обозначается, как: \"$\\leftarrow$\")\n",
    "2. После расчета $\\operatorname{D}(i, j)$ для малых $i$ и $j$ мы рассчитываем значения расстояния для бОльших $i$ и $j$ на основе рекурсивной формулы: \n",
    "\n",
    "$$\\qquad\\operatorname{D}(i,j) =  \\min \\begin{cases}\n",
    "          \\operatorname{D}(i-1,j) + 1 \\text{, операция удаления, на схеме обозначается как: } \\uparrow\\\\\n",
    "          \\operatorname{D}(i,j-1) + 1 \\text{, операция вставки, на схеме обозначается как: } \\leftarrow\\\\\n",
    "          \\operatorname{D}(i-1,j-1) + \\operatorname{m}(S_1[i], S_2[j]) \\text{, операция замены, на схеме обозначается как: } \\nwarrow\n",
    "       \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>         \n",
    "    <img src=\"./img/levinst3.png\" alt=\"Пример поиска расстояния Левинштейна\" style=\"width: 800px;\"/>\n",
    "    <b>Пример поиска расстояния Левинштейна для слов \"intention\" и \"execution\" с помощью алгоритма Вагнера - Фишера</b>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>         \n",
    "    <img src=\"./img/levinst4.png\" alt=\"Алгоритм Вагнера - Фишера для поиска расстояния Левинштейна\" style=\"width: 500px;\"/>\n",
    "    <b>Алгоритм Вагнера - Фишера для поиска расстояния Левинштейна</b>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# from nltk.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import (\n",
    "    edit_distance,\n",
    "    edit_distance_align,\n",
    "    binary_distance,\n",
    "    jaccard_distance,\n",
    "    masi_distance,\n",
    "    interval_distance,\n",
    "    custom_distance,\n",
    "    presence,\n",
    "    fractional_presence,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('intention', 'execution', substitution_cost=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# результат при substitution_cost=1\n",
    "edit_distance('intention', 'execution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance('пирвет', 'привет', substitution_cost=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# расстояние Домрау-Левинштайна:\n",
    "edit_distance('пирвет', 'привет', substitution_cost=2, transpositions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'intention'\n",
    "s2 = 'execution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 0),\n",
       " (2, 0),\n",
       " (3, 0),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 3),\n",
       " (4, 4),\n",
       " (5, 5),\n",
       " (6, 6),\n",
       " (7, 7),\n",
       " (8, 8),\n",
       " (9, 9)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed = edit_distance_align(s1, s2, substitution_cost=2)\n",
    "ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intention'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'n', 't', 'e', 'n', 't', 'i', 'o', 'n']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = list(s1)\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intention'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ''.join(l1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = l1\n",
    "i = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'int_e_ntion'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh_res = ''.join('_'+s+'_' if ind==i else s for ind, s in enumerate(res))\n",
    "sh_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ed_path(as1, as2, ed):\n",
    "    s1 = '#' + as1 # shift index\n",
    "    s2 = '#' + as2 # shift index   \n",
    "    ip,  jp = ed[0]\n",
    "    res = list(s1)\n",
    "    cost = 0\n",
    "    print(f'i:{ip}, j:{jp}; init, cost: {cost}; res: {\"\".join(res)[1:]}')\n",
    "    def sh_res(res, i):\n",
    "        return ''.join(s.upper() if ind==i else s for ind, s in enumerate(res))[1:]\n",
    "        \n",
    "    for i, j in ed[1:]:\n",
    "        if i == ip+1 and j == jp+1:\n",
    "            if s1[i] == s2[j]:\n",
    "                # res = res\n",
    "                cost += 0\n",
    "                print(f'i:{i}, j:{j}; save {s1[i]}, cost: {cost}; res: {sh_res(res, j)}')\n",
    "            else:\n",
    "                res[j] = s2[j]\n",
    "                cost += 2\n",
    "                print(f'i:{i}, j:{j}; change {s1[i]} -> {s2[j]}; cost: {cost}; res: {sh_res(res, j)}')\n",
    "        elif i == ip+1 and j == jp:\n",
    "            cost += 1            \n",
    "            print(f'i:{i}, j:{j}; remove {res[j+1]}, cost: {cost}; res: {sh_res(res, j+1)}')            \n",
    "            rs = res.pop(j+1)\n",
    "        elif i == ip and j == jp+1:\n",
    "            rs = res.insert(j, s2[j])\n",
    "            cost += 1\n",
    "            print(f'i:{i}, j:{j}; insert {s2[j]}, cost: {cost}; res: {sh_res(res, j)}')            \n",
    "        else:\n",
    "            assert False, f'i: {i}, j: {j}; ip: {ip}, jp: {jp}'\n",
    "        ip = i\n",
    "        jp = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 0),\n",
       " (2, 0),\n",
       " (3, 0),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 3),\n",
       " (4, 4),\n",
       " (5, 5),\n",
       " (6, 6),\n",
       " (7, 7),\n",
       " (8, 8),\n",
       " (9, 9)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s1 = 'abcd'\n",
    "# s2 = 'acfg'\n",
    "\n",
    "s1 = 'intention'\n",
    "s2 = 'execution'\n",
    "da = edit_distance_align(s1, s2, substitution_cost=2)\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:0, j:0; init, cost: 0; res: intention\n",
      "i:1, j:0; remove i, cost: 1; res: Intention\n",
      "i:2, j:0; remove n, cost: 2; res: Ntention\n",
      "i:3, j:0; remove t, cost: 3; res: Tention\n",
      "i:4, j:1; save e, cost: 3; res: Ention\n",
      "i:4, j:2; insert x, cost: 4; res: eXntion\n",
      "i:4, j:3; insert e, cost: 5; res: exEntion\n",
      "i:4, j:4; insert c, cost: 6; res: exeCntion\n",
      "i:5, j:5; change n -> u; cost: 8; res: execUtion\n",
      "i:6, j:6; save t, cost: 8; res: execuTion\n",
      "i:7, j:7; save i, cost: 8; res: executIon\n",
      "i:8, j:8; save o, cost: 8; res: executiOn\n",
      "i:9, j:9; save n, cost: 8; res: executioN\n"
     ]
    }
   ],
   "source": [
    "show_ed_path(s1, s2, da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С точки зрения приложений определение расстояния Левенштейна между словами или строками обладает следующими недостатками:\n",
    "* При перестановке местами слов или частей слов получаются сравнительно большие расстояния.\n",
    "* Расстояния между совершенно разными короткими словами оказываются небольшими, в то время как расстояния между очень похожими длинными словами оказываются значительными.\n",
    "\n",
    "Другие метрики в NLTK: http://www.nltk.org/howto/metrics.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стемминг и лемматизация <a class=\"anchor\" id=\"стемминг\"></a>\n",
    "\n",
    "-\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто необходимо обрабатывать разные формы слова одинаково. В этом случае поможет переход от словоформ к их леммам (словарным формам лексем) или основам (ядерным частям слова, за вычетом словоизменительных морфем)\n",
    "\n",
    "Например, при поиске: по запросам “кошками” и “кошкам” ожидаются одинаковые ответы.\n",
    "\n",
    "* __Стемминг__ - это процесс нахождения основы слова, которая не обязательно совпадает с корнем слова.\n",
    "* __Лемматизация__ - приведение слова к словарной форме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Морфология__ - это раздел лингвистики, который изучает структуру слов и их морфологические характеристики. Классическая морфология проанализирует слово _собака_ примерно так: это существительное женского рода, оно состоит из _корня_ собак и _окончания_ а, окончание показывает, что слово употреблено в единственном числе и в именительном падеже. \n",
    "\n",
    "__Компьютерная морфология__ анализирует и синтезирует слова программными средствами. В наиболее привычной формулировке под морфологическим анализом слова подразумевается:\n",
    "* определение леммы (базовой, канонической формы слова)\n",
    "* определение грамматических характеристик слова. \n",
    "\n",
    "В области автоматической обработки данных также используется термин __нормализация__, обозначающий постановку слова или словосочетания в __каноническую форму__ (грамматические характеристики исходной формы при этом не выдаются). Обратная задача, т. е . постановка леммы в нужную грамматическую форму, называется __порождением словоформы__. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стемминг <a class=\"anchor\" id=\"cтемминг_\"></a>\n",
    "-\n",
    "\n",
    "[к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Стемминг__ отбрасывает суффиксы и окончания до неизменяемой формы слова \n",
    "\n",
    "Примеры: \n",
    "* кошка -> кошк \n",
    "* кошками -> кошк \n",
    "* пылесосы -> пылесос\n",
    "\n",
    "В школьной грамматике __основой__ считается __часть слова без окончания__. \n",
    "* В большинстве случаев она не меняется при грамматических изменениях самого слова — так ведет себя, например, основа _слон_ в словоформах: _слон, слону, слонами, слонов_. \n",
    "* Но в некоторых словах основа может изменяться. Например, для словоформ _день, дню и дне_ основами будут ден-, дн- и дн-, такое явление называется __чередованием__. \n",
    "Поэтому самый популярный на сегодня подход использует псевдоосновы (или машинные основы). Это неизменяемые начальные части слов. Для слова день такой неизменяемой частью будет _д-_. Формы некоторых слов могут образовываться от разных корней. Например, у слова _ходить_ есть форма _шел_. Это называется _супплетивизмом_. \n",
    "\n",
    "__В русском языке__ супплетивизм и чередования очень распространены, поэтому __псевдоосновы часто получаются очень короткими__. __Для русского языка стемминг работает гораздо хуже, чем лемматизация__. \n",
    "\n",
    "В стемминге есть только правила обрабатывания суффиксов и, возможно, небольшие словари исключений. Существует бесплатный инструмент для написания стеммеров — Snowball. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Snowball - Наиболее распространенный стеммер из проекта Apache Lucene \n",
    "# Работает для нескольких языков, включая русский\n",
    "from nltk.stem import SnowballStemmer\n",
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кошк\n",
      "кошечк\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "snb_stemmer_ru = SnowballStemmer('russian')\n",
    "print(snb_stemmer_ru.stem('кошку'))\n",
    "print(snb_stemmer_ru.stem('кошечки'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Постгуманизм — рациональное мировоззрение, основанное на представлении, что эволюция человека не завершена и может быть продолжена в будущем. Эволюционное развитие должно привести к становлению постчеловека — гипотетической стадии эволюции человеческого вида, строение и возможности которого стали бы отличными от современных человеческих в результате активного использования передовых технологий преобразования человека. Постгуманизм признаёт неотъемлемыми правами совершенствование человеческих возможностей (физиологических, интеллектуальных и т. п.) и достижение физического бессмертия. В отличие от трансгуманизма, под определением постгуманизма также понимается критика классического гуманизма, подчёркивающая изменение отношения человека к себе, обществу, окружающей среде и бурно развивающимся технологиям, но окончательно разница между транс- и постгуманизмом не определена и остаётся предметом дискуссий.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# загружаем текст:\n",
    "with open('phm.txt ') as f:\n",
    "    lines = [l for l in f]\n",
    "print(len(lines))\n",
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import sentenize\n",
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['постгуманизм',\n",
       " 'рациональн',\n",
       " 'мировоззрен',\n",
       " 'основа',\n",
       " 'на',\n",
       " 'представлен',\n",
       " 'что',\n",
       " 'эволюц',\n",
       " 'человек',\n",
       " 'не',\n",
       " 'заверш',\n",
       " 'и',\n",
       " 'может',\n",
       " 'быт',\n",
       " 'продолж',\n",
       " 'в',\n",
       " 'будущ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snt = list(sentenize(lines[0]))\n",
    "tok = list(tokenize(snt[0].text))\n",
    "w = re.compile('^[а-яА-ЯёЁ]*$')\n",
    "# предложение превращено в последовательность стем русских слов:\n",
    "[snb_stemmer_ru.stem(t.text) for t in tok if w.search(t.text)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snowball использует __систему суффиксов и окончаний__ для предсказания части речи и грамматических параметров. Так как одно и\n",
    "то же окончание может принадлежать разным частям речи или различным парадигмам, его оказывается недостаточно для точного предсказания. Применение суффиксов позволяет повысить точность.\n",
    "\n",
    "Система реализовывается на языке программирования в виде большого количества условных операторов, анализирующих самый длинный постфикс и его контекст. По окончании анализа слову приписывается часть речи и набор параметров, а найденное окончание (или псевдоокончание) отрезается. В итоге, помимо параметров, система возвращает стем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация <a class=\"anchor\" id=\"лемматизация\"></a>\n",
    "\n",
    "-\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Лемматизация__\n",
    "\n",
    "У разных слов часто совпадает основа: \n",
    "* пол : полу , пола , поле , полю , поля , пол , полем , полях , полям \n",
    "* лев : левый, левая, лев \n",
    "\n",
    "Из-за этого увеличивается многозначность и ухудшаются результаты работы приложений.\n",
    "\n",
    "Лемматизация - приведение слова к словарной форме, например: \n",
    "* кошки -> кошка \n",
    "* кошками -> кошка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Морфологические анализаторы для русского языка:\n",
    "\n",
    "|Название |Open |Доб. словари |Объем слов. |Скорость | Python? |\n",
    "|------|------|------|------|------|------|\n",
    "|AOT | Y | N | 160 тыс.| 60-90 | N |\n",
    "|MyStem | N | Y/N | >250 тыс.| 100-120 | Есть оболочка на Python |\n",
    "|Pymorphy2 | Y | N | 250 тыс.| 80-100 | Y|\n",
    "|TreeTagger | N | Y | 210 тыс.| 20-25 | N |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__pymorphy2__ \n",
    "\n",
    "* Код проекта: https://github.com/kmike/pymorphy2\n",
    "\n",
    "* Документация проекта: https://pymorphy2.readthedocs.io/en/stable/\n",
    "\n",
    "_pip install pymorphy2_\n",
    "\n",
    "Словари распространяются отдельными пакетами. Для русского языка:\n",
    "\n",
    "_pip install -U pymorphy2-dicts-ru_\n",
    "\n",
    "Есть оптимизированная версия, потребуется настроенное окружение для сборки (компилятор C/C++ и т.д.).\n",
    "\n",
    "Морфологический процессор с открытым исходным кодом, предоставляет все функции полного морфологического анализа и\n",
    "синтеза словоформ. Он умеет:\n",
    "* приводить слово к нормальной форме (например, “люди -> человек”, или “гулял -> гулять”).\n",
    "* ставить слово в нужную форму. Например, ставить слово во множественное число, менять падеж слова и т.д.\n",
    "* возвращать грамматическую информацию о слове (число, род, падеж, часть речи и т.д.)\n",
    "\n",
    "При работе используется словарь OpenCorpora; для незнакомых слов строятся гипотезы. Библиотека достаточно быстрая: в настоящий момент скорость работы - от нескольких тыс слов/сек до > 100тыс слов/сек (в зависимости от выполняемой операции, интерпретатора и установленных пакетов); потребление памяти - 10…20Мб; полностью поддерживается буква ё. Словарь OpenCorpora содержит около 250 тыс. лемм, а также является полностью открытым и регулярно пополняемым.\n",
    "\n",
    "Для анализа неизвестных слов в Pymorphy2 используются несколько методов, которые применяются последовательно. Изначально от слова отсекается префикс из набора известных префиксов и если остаток слова был найден в словаре, то отсеченный префикс приписывается к результатам разбора. Если этот метод не сработал, то аналогичные действия выполняются для префикса слова длиной от 1 до 5, даже если такой префикс является неизвестным. Затем, в случае неудачи, словоформа разбирается по окончанию. Для этого используется дополнительный автомат всех окончаний, встречающихся в словаре с имеющимися разборами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='стали', tag=OpencorporaTag('VERB,perf,intr plur,past,indc'), normal_form='стать', score=0.975342, methods_stack=((DictionaryAnalyzer(), 'стали', 945, 4),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,gent'), normal_form='сталь', score=0.010958, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 1),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn plur,nomn'), normal_form='сталь', score=0.005479, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 6),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,datv'), normal_form='сталь', score=0.002739, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 2),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn sing,loct'), normal_form='сталь', score=0.002739, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 5),)),\n",
       " Parse(word='стали', tag=OpencorporaTag('NOUN,inan,femn plur,accs'), normal_form='сталь', score=0.002739, methods_stack=((DictionaryAnalyzer(), 'стали', 13, 9),))]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = morph.parse('стали')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpencorporaTag('VERB,perf,intr plur,past,indc')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0].tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод MorphAnalyzer.parse() возвращает один или несколько объектов типа Parse с информацией о том, как слово может быть разобрано.\n",
    "\n",
    "__Тег__ - это набор граммем, характеризующих данное слово. Например, тег 'VERB,perf,intr plur,past,indc' означает, что слово - глагол (VERB) совершенного вида (perf), непереходный (intr), множественного числа (plur), прошедшего времени (past), изъявительного наклонения (indc). Доступные граммемы описаны тут: https://pymorphy2.readthedocs.io/en/latest/user/grammemes.html#grammeme-docs.\n",
    "\n",
    "Далее: https://pymorphy2.readthedocs.io/en/latest/user/guide.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score - это оценка P(tag|word), оценка вероятности того, что данный разбор правильный.\n",
    "\n",
    "Разборы сортируются по убыванию score, поэтому везде в примерах берется первый вариант разбора из возможных. Оценки P(tag|word) помогают улучшить разбор, но их недостаточно для надежного снятия неоднозначности, как минимум по следующим причинам:\n",
    "\n",
    "то, как нужно разбирать слово, зависит от соседних слов; pymorphy2 работает только на уровне отдельных слов;\n",
    "условная вероятность P(tag|word) оценена на основе сбалансированного набора текстов; в специализированных текстах вероятности могут быть другими - например, возможно, что в металлургических текстах P(NOUN|стали) > P(VERB|стали);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parse(word='стать', tag=OpencorporaTag('INFN,perf,intr'), normal_form='стать', score=1.0, methods_stack=((DictionaryAnalyzer(), 'стать', 945, 0),))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#у каждого разбора есть нормальная форма, которую можно получить, обратившись к атрибутам normal_form или normalized:\n",
    "p[0].normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['постгуманизм',\n",
       " 'рациональный',\n",
       " 'мировоззрение',\n",
       " 'основать',\n",
       " 'на',\n",
       " 'представление',\n",
       " 'что',\n",
       " 'эволюция',\n",
       " 'человек',\n",
       " 'не',\n",
       " 'завершить',\n",
       " 'и',\n",
       " 'мочь',\n",
       " 'быть',\n",
       " 'продолжить',\n",
       " 'в',\n",
       " 'будущее']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snt = list(sentenize(lines[0]))\n",
    "tok = list(tokenize(snt[0].text))\n",
    "w = re.compile('^[а-яА-ЯёЁ]*$')\n",
    "# предложение превращено в последовательность нормальных форм русских слов:\n",
    "pt = [morph.parse(t.text) for t in tok if w.search(t.text)] \n",
    "[w[0].normalized.word for w in pt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стоп-слова <a class=\"anchor\" id=\"стоп\"></a>\n",
    "\n",
    "-\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Закон Ципфа__\n",
    "\n",
    "__Закон Ципфа__ (Zipf's law, «ранг-частота») - эмперический закон, наблюдаемый для различных объектов в области физики, социологии, лингвистики и т.д., указывающий на то, что характеристики объектов (в частности, частота появлвения) имеют вид близкий к распределению Ципфа. \n",
    "\n",
    "Распределение Ципфа - это дискретный закон распределения, имеющий степенную природу и близкий (но не идентичный) Дзета-распределени. \n",
    "\n",
    "Пусть:\n",
    "* $N$ - количестов различных объектов (например, различных слов в тексте);\n",
    "* $k$ - ранг, т.е. порядоквый номер объекта (например, слова), в отсортированной по частоте последовательности объектов;\n",
    "* $s$ - параметр распределения, отражающий степень убывания частоты.\n",
    "\n",
    "тогда распрпеделение имеет вид:\n",
    "\n",
    "$$f(k;s,N)=\\frac{1/k^s}{\\sum\\limits_{n=1}^N (1/n^s)}$$\n",
    "\n",
    "Свойство объектов распределенных по этому закону:\n",
    "* $P_k$ - частота встречаемости объекта с рангом $k$\n",
    "\n",
    "$$P_k=P_1/k^s$$\n",
    "\n",
    "* при $s=1$:\n",
    "\n",
    "$$P_k=P_1/k$$\n",
    "\n",
    "__Закон Ципфа в лингвистике__ - эмпирическая закономерность распределения частоты слов естественного языка: если все слова языка (или просто достаточно длинного текста) упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n (так называемому рангу этого слова. \n",
    "\n",
    "Например: \n",
    "* второе по используемости слово встречается примерно в два раза реже, чем первое\n",
    "* третье - в три раза реже, чем первое (и так далее ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В естественных языках частоты слов имеют очень тяжелые ховосты и могут описываться распределением Ципфа с $s \\to 1$ при $N \\to \\infty$ в случае если $s > 1$:\n",
    "$$\\zeta (s) = \\sum_{n=1}^\\infty \\frac{1}{n^s}<\\infty$$\n",
    "где $\\zeta$ это Дзета-функция Римана.\n",
    "\n",
    "В этом случае распределение Ципфа можно заменить Дзета распределением (дискретным распределением, в котором $k \\in [1, \\infty])$): \n",
    "$$P(x=k; s) = \\frac {k^{-s}} {\\zeta(s)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>         \n",
    "    <img src=\"./img/ZipfsLaw.png\" alt=\"Пример поиска расстояния Левинштейна\" style=\"width: 500px;\"/>\n",
    "    <b>Пример: (распределение частот слов в статьях русской Википедии)</b>\n",
    "</center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<center>         \n",
    "    <img src=\"./img/ZipfsLaw2.png\" alt=\"Пример поиска расстояния Левинштейна\" style=\"width: 500px;\"/>\n",
    "    <b>Пример (распределение частот слов в крупном художесвтенном произведении)</b>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Стоп-слова__\n",
    "\n",
    "* Для крупных текстов большинство слов из головы распределения обычно характеризуют язык, а не текст\n",
    "* Обычно это служебные слова, определяющие стрктуру предложения (например: предлоги, артикли, частицы), местоимения (фактически, универсальные указатели) и  самые общие понятия используемые в письменной речи\n",
    "* Во многих задачах использование наиболее частотных слов создает шум и их выгодно исключать из рассмотрения. За такими словами закрепился теримн __стоп-слова__(stop words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> \n",
    "<b>Пример стоп-слов русского языка:</b>\n",
    "<br/>\n",
    "(конкретный состав стоп-слов зависит от рассматриваемого корпуса текстов, длинны списка и т.д.)\n",
    "</center>\n",
    "\n",
    "<table>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt; width: 48pt;\" width=\"64\">-</td>   <td style=\"background-color: #eeeeee; width: 48pt;\" width=\"64\">еще</td>   <td style=\"background-color: #eeeeee; width: 48pt;\" width=\"64\">него</td>   <td style=\"background-color: #eeeeee; width: 48pt;\" width=\"64\">сказать</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">а</td>   <td style=\"background-color: #eeeeee;\">ж</td>   <td style=\"background-color: #eeeeee;\">нее</td>   <td style=\"background-color: #eeeeee;\">со</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">без</td>   <td style=\"background-color: #eeeeee;\">же</td>   <td style=\"background-color: #eeeeee;\">ней</td>   <td style=\"background-color: #eeeeee;\">совсем</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">более</td>   <td style=\"background-color: #eeeeee;\">жизнь</td>   <td style=\"background-color: #eeeeee;\">нельзя</td>   <td style=\"background-color: #eeeeee;\">так</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">больше</td>   <td style=\"background-color: #eeeeee;\">за</td>   <td style=\"background-color: #eeeeee;\">нет</td>   <td style=\"background-color: #eeeeee;\">такой</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">будет</td>   <td style=\"background-color: #eeeeee;\">зачем</td>   <td style=\"background-color: #eeeeee;\">ни</td>   <td style=\"background-color: #eeeeee;\">там</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">будто</td>   <td style=\"background-color: #eeeeee;\">здесь</td>   <td style=\"background-color: #eeeeee;\">нибудь</td>   <td style=\"background-color: #eeeeee;\">тебя</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">бы</td>   <td style=\"background-color: #eeeeee;\">и</td>   <td style=\"background-color: #eeeeee;\">никогда</td>   <td style=\"background-color: #eeeeee;\">тем</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">был</td>   <td style=\"background-color: #eeeeee;\">из</td>   <td style=\"background-color: #eeeeee;\">ним</td>   <td style=\"background-color: #eeeeee;\">теперь</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">была</td>   <td style=\"background-color: #eeeeee;\">из-за</td>   <td style=\"background-color: #eeeeee;\">них</td>   <td style=\"background-color: #eeeeee;\">то</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">были</td>   <td style=\"background-color: #eeeeee;\">или</td>   <td style=\"background-color: #eeeeee;\">ничего</td>   <td style=\"background-color: #eeeeee;\">тогда</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">было</td>   <td style=\"background-color: #eeeeee;\">им</td>   <td style=\"background-color: #eeeeee;\">но</td>   <td style=\"background-color: #eeeeee;\">того</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">быть</td>   <td style=\"background-color: #eeeeee;\">иногда</td>   <td style=\"background-color: #eeeeee;\">ну</td>   <td style=\"background-color: #eeeeee;\">тоже</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">в</td>   <td style=\"background-color: #eeeeee;\">их</td>   <td style=\"background-color: #eeeeee;\">о</td>   <td style=\"background-color: #eeeeee;\">только</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">вам</td>   <td style=\"background-color: #eeeeee;\">к</td>   <td style=\"background-color: #eeeeee;\">об</td>   <td style=\"background-color: #eeeeee;\">том</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">вас</td>   <td style=\"background-color: #eeeeee;\">кажется</td>   <td style=\"background-color: #eeeeee;\">один</td>   <td style=\"background-color: #eeeeee;\">тот</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">вдруг</td>   <td style=\"background-color: #eeeeee;\">как</td>   <td style=\"background-color: #eeeeee;\">он</td>   <td style=\"background-color: #eeeeee;\">три</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">ведь</td>   <td style=\"background-color: #eeeeee;\">какая</td>   <td style=\"background-color: #eeeeee;\">она</td>   <td style=\"background-color: #eeeeee;\">тут</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">во</td>   <td style=\"background-color: #eeeeee;\">какой</td>   <td style=\"background-color: #eeeeee;\">они</td>   <td style=\"background-color: #eeeeee;\">ты</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">вот</td>   <td style=\"background-color: #eeeeee;\">когда</td>   <td style=\"background-color: #eeeeee;\">опять</td>   <td style=\"background-color: #eeeeee;\">у</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">впрочем</td>   <td style=\"background-color: #eeeeee;\">конечно</td>   <td style=\"background-color: #eeeeee;\">от</td>   <td style=\"background-color: #eeeeee;\">уж</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">все</td>   <td style=\"background-color: #eeeeee;\">которого</td>   <td style=\"background-color: #eeeeee;\">перед</td>   <td style=\"background-color: #eeeeee;\">уже</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">всегда</td>   <td style=\"background-color: #eeeeee;\">которые</td>   <td style=\"background-color: #eeeeee;\">по</td>   <td style=\"background-color: #eeeeee;\">хорошо</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">всего</td>   <td style=\"background-color: #eeeeee;\">кто</td>   <td style=\"background-color: #eeeeee;\">под</td>   <td style=\"background-color: #eeeeee;\">хоть</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">всех</td>   <td style=\"background-color: #eeeeee;\">куда</td>   <td style=\"background-color: #eeeeee;\">после</td>   <td style=\"background-color: #eeeeee;\">чего</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">всю</td>   <td style=\"background-color: #eeeeee;\">ли</td>   <td style=\"background-color: #eeeeee;\">потом</td>   <td style=\"background-color: #eeeeee;\">человек</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">вы</td>   <td style=\"background-color: #eeeeee;\">лучше</td>   <td style=\"background-color: #eeeeee;\">потому</td>   <td style=\"background-color: #eeeeee;\">чем</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">г</td>   <td style=\"background-color: #eeeeee;\">между</td>   <td style=\"background-color: #eeeeee;\">почти</td>   <td style=\"background-color: #eeeeee;\">через</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">где</td>   <td style=\"background-color: #eeeeee;\">меня</td>   <td style=\"background-color: #eeeeee;\">при</td>   <td style=\"background-color: #eeeeee;\">что</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">говорил</td>   <td style=\"background-color: #eeeeee;\">мне</td>   <td style=\"background-color: #eeeeee;\">про</td>   <td style=\"background-color: #eeeeee;\">чтоб</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">да</td>   <td style=\"background-color: #eeeeee;\">много</td>   <td style=\"background-color: #eeeeee;\">раз</td>   <td style=\"background-color: #eeeeee;\">чтобы</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">даже</td>   <td style=\"background-color: #eeeeee;\">может</td>   <td style=\"background-color: #eeeeee;\">разве</td>   <td style=\"background-color: #eeeeee;\">чуть</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">два</td>   <td style=\"background-color: #eeeeee;\">можно</td>   <td style=\"background-color: #eeeeee;\">с</td>   <td style=\"background-color: #eeeeee;\">эти</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">для</td>   <td style=\"background-color: #eeeeee;\">мой</td>   <td style=\"background-color: #eeeeee;\">сам</td>   <td style=\"background-color: #eeeeee;\">этого</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">до</td>   <td style=\"background-color: #eeeeee;\">моя</td>   <td style=\"background-color: #eeeeee;\">свое</td>   <td style=\"background-color: #eeeeee;\">этой</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">другой</td>   <td style=\"background-color: #eeeeee;\">мы</td>   <td style=\"background-color: #eeeeee;\">свою</td>   <td style=\"background-color: #eeeeee;\">этом</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">его</td>   <td style=\"background-color: #eeeeee;\">на</td>   <td style=\"background-color: #eeeeee;\">себе</td>   <td style=\"background-color: #eeeeee;\">этот</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">ее</td>   <td style=\"background-color: #eeeeee;\">над</td>   <td style=\"background-color: #eeeeee;\">себя</td>   <td style=\"background-color: #eeeeee;\">эту</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">ей</td>   <td style=\"background-color: #eeeeee;\">надо</td>   <td style=\"background-color: #eeeeee;\">сегодня</td>   <td style=\"background-color: #eeeeee;\">я</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">ему</td>   <td style=\"background-color: #eeeeee;\">наконец</td>   <td style=\"background-color: #eeeeee;\">сейчас</td>   <td style=\"background-color: #eeeeee;\"><br>\n",
    "</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">если</td>   <td style=\"background-color: #eeeeee;\">нас</td>   <td style=\"background-color: #eeeeee;\">сказал</td>   <td style=\"background-color: #eeeeee;\"><br>\n",
    "</td>  </tr>\n",
    "<tr height=\"20\" style=\"height: 15pt;\">   <td height=\"20\" style=\"background-color: #eeeeee; height: 15pt;\">есть</td>   <td style=\"background-color: #eeeeee;\">не</td>   <td style=\"background-color: #eeeeee;\">сказала</td>   <td style=\"background-color: #eeeeee;\"><br>\n",
    "</td>  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install -U nltk\n",
    "import nltk\n",
    "nltk.__version__\n",
    "# # nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alpha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка списков стоп-слов в NLTK:\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "ru_stop_words = stopwords.words('russian')\n",
    "print(ru_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мешок слов <a class=\"anchor\" id=\"мешок\"></a>\n",
    "\n",
    "-\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Мешок слов__ (bag-of-words, BoW) – модель, которая используется при обработке естественного языка для представления текста. Для представления текста ведется подсчет того, сколько раз каждое отдельное слово появляется в тексте, таким образом текст преобразуется в вектор, координатами которого являются рассматриваемые слова, а значениями - частоты слов. \n",
    "* Любая информация о порядке или структуре слов в документе отбрасывается. Модель касается только того, встречаются ли в документе известные слова, а не где в документе.\n",
    "    * Интуиция заключается в том, что документы похожи, если они имеют похожее содержание.\n",
    "* Модели мешка слов могут отличаться способами в определении словарного запаса известных слов (или токенов) и в том, как оценивать наличие известных слов.\n",
    "* Перед подсчетом можно применить методы предварительной обработки, описанные в выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools as it\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем все интересные нам токены:\n",
    "w_regex = re.compile('^[а-яА-ЯёЁ]*$') # re.compile('^[а-яА-ЯёЁ,\\.]*$')\n",
    "with open(\"AnnaKarenina_.txt\", encoding=\"cp1251\") as f:\n",
    "    book_tokens = [t.text.lower() for t in tokenize(f.read()) if w_regex.search(t.text)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266954 ['лев', 'николаевич', 'толстой', 'анна', 'каренина', 'мне', 'отмщение', 'и', 'аз', 'воздам', 'часть', 'первая', 'все', 'счастливые', 'семьи', 'похожи', 'друг', 'на', 'друга', 'каждая', 'несчастливая', 'семья', 'несчастлива', 'все', 'смешалось', 'в', 'доме', 'облонских', 'жена', 'узнала', 'что', 'муж', 'был', 'в', 'связи', 'с', 'бывшею', 'в', 'их', 'доме', 'и', 'объявила', 'мужу', 'что', 'не', 'может', 'жить', 'с', 'ним', 'в', 'одном', 'доме', 'положение', 'это', 'продолжалось', 'уже', 'третий', 'день', 'и', 'мучительно', 'чувствовалось', 'и', 'самими', 'супругами', 'и', 'всеми', 'членами', 'семьи', 'и', 'домочадцами', 'все', 'члены', 'семьи', 'и', 'домочадцы', 'чувствовали', 'что', 'нет', 'смысла', 'в', 'их', 'сожительстве', 'и', 'что', 'на', 'каждом', 'постоялом', 'дворе', 'случайно', 'сошедшиеся', 'люди', 'более', 'связаны', 'между', 'собой', 'чем', 'они', 'члены', 'семьи', 'и', 'домочадцы', 'облонских', 'жена', 'не', 'выходила', 'из', 'своих', 'комнат', 'мужа', 'третий', 'день', 'не', 'было', 'дома', 'дети', 'бегали', 'по', 'всему', 'дому', 'как', 'потерянные', 'англичанка', 'поссорилась', 'с', 'экономкой', 'и', 'написала', 'записку', 'приятельнице', 'прося', 'приискать', 'ей', 'новое', 'место', 'повар', 'ушел', 'еще', 'вчера', 'со', 'двора', 'во', 'время', 'обеда', 'черная', 'кухарка', 'и', 'кучер', 'просили', 'расчета', 'на']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(print(len(book_tokens), book_tokens[:150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.nltk.org/api/nltk.html#nltk.probability.FreqDist\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(book_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработано токенов:266954; найдено различных токенов:32569\n"
     ]
    }
   ],
   "source": [
    "print(f'Обработано токенов:{fdist.N()}; найдено различных токенов:{fdist.B()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Содержимое: [('лев', 1), ('николаевич', 2), ('толстой', 2), ('анна', 499), ('каренина', 45), ('мне', 682), ('отмщение', 1), ('и', 12916), ('аз', 1), ('воздам', 1)]\n"
     ]
    }
   ],
   "source": [
    "print('Содержимое:', list(it.islice(fdist.items(), 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самое частое слово:и,  частота слова \"анна\":499\n"
     ]
    }
   ],
   "source": [
    "print(f'Самое частое слово:{fdist.max()},  частота слова \"анна\":{fdist.get(\"анна\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('и', 12916), ('не', 6537), ('что', 5765), ('в', 5720), ('он', 5551), ('на', 3594), ('она', 3434), ('с', 3327), ('я', 3212), ('как', 2660), ('но', 2581), ('его', 2578), ('это', 2223), ('к', 1983), ('ее', 1805), ('все', 1671), ('было', 1656), ('так', 1415), ('сказал', 1412), ('а', 1391), ('то', 1388), ('же', 1325), ('ему', 1252), ('о', 1243), ('за', 1139), ('левин', 1135), ('только', 1017), ('ты', 993), ('у', 913), ('был', 901), ('по', 834), ('когда', 831), ('для', 827), ('сказала', 827), ('бы', 822), ('от', 813), ('да', 812), ('теперь', 810), ('вы', 756), ('из', 735), ('была', 728), ('еще', 699), ('ей', 689), ('мне', 682), ('кити', 661), ('они', 646), ('него', 622), ('уже', 601), ('нет', 592), ('очень', 573)]\n"
     ]
    }
   ],
   "source": [
    "print(fdist.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в мешке слов большинство самых частотных слов - стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['лев', 'николаевич', 'толстой', 'анна', 'каренина', 'отмщение', 'аз', 'воздам', 'часть', 'первая', 'счастливые', 'семьи', 'похожи', 'друг', 'друга', 'каждая', 'несчастливая', 'семья', 'несчастлива', 'смешалось', 'доме', 'облонских', 'жена', 'узнала', 'муж', 'связи', 'бывшею', 'доме', 'объявила', 'мужу', 'жить', 'одном', 'доме', 'положение', 'это', 'продолжалось', 'третий', 'день', 'мучительно', 'чувствовалось', 'самими', 'супругами', 'всеми', 'членами', 'семьи', 'домочадцами', 'члены', 'семьи', 'домочадцы', 'чувствовали', 'смысла', 'сожительстве', 'каждом', 'постоялом', 'дворе', 'случайно', 'сошедшиеся', 'люди', 'связаны', 'собой', 'члены', 'семьи', 'домочадцы', 'облонских', 'жена', 'выходила', 'своих', 'комнат', 'мужа', 'третий', 'день', 'дома', 'дети', 'бегали', 'всему', 'дому', 'потерянные', 'англичанка', 'поссорилась', 'экономкой', 'написала', 'записку', 'приятельнице', 'прося', 'приискать', 'новое', 'место', 'повар', 'ушел', 'вчера', 'двора', 'время', 'обеда', 'черная', 'кухарка', 'кучер', 'просили', 'расчета']\n"
     ]
    }
   ],
   "source": [
    "ru_stop_words_s = set(ru_stop_words)\n",
    "# фильтруем стоп-слова:\n",
    "wtokens_wostw = [w for w in book_tokens[:150] if w not in ru_stop_words_s]\n",
    "print(wtokens_wostw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12, 'это', 2223), (18, 'сказал', 1412), (25, 'левин', 1135), (33, 'сказала', 827), (44, 'кити', 661), (49, 'очень', 573), (53, 'вронский', 509), (56, 'анна', 499), (66, 'алексей', 429), (68, 'степан', 423), (69, 'аркадьич', 422), (72, 'александрович', 395), (81, 'время', 366), (82, 'мог', 357), (83, 'говорил', 357), (89, 'руку', 309), (90, 'долли', 302), (92, 'которые', 295), (97, 'лицо', 277), (98, 'сказать', 276), (102, 'дело', 272), (103, 'левина', 272), (108, 'который', 263), (111, 'своей', 251), (113, 'знал', 249), (116, 'жизни', 235), (117, 'говорить', 234), (118, 'знаю', 233), (121, 'которое', 231), (124, 'пред', 224), (125, 'хотел', 219), (127, 'сергей', 219), (129, 'нужно', 217), (130, 'человек', 215), (131, 'прежде', 215), (132, 'глаза', 214), (134, 'могу', 214), (135, 'видел', 214), (137, 'тебе', 213), (139, 'тотчас', 211), (141, 'чувствовал', 210), (143, 'вронского', 205), (145, 'одно', 202), (146, 'своего', 199), (147, 'могла', 199), (148, 'свое', 198), (149, 'иванович', 191), (153, 'думал', 189), (154, 'глядя', 189), (156, 'говорила', 184)]\n"
     ]
    }
   ],
   "source": [
    "# самые частотные слова \"Анны Карениной\" после очистки от стоп-слов:\n",
    "print(list(it.islice(((i, w, f) for i, (w, f) in enumerate(fdist.most_common(500)) \\\n",
    "                      if w not in ru_stop_words_s), 50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторное представление документа <a class=\"anchor\" id=\"векторный-документ\"></a>\n",
    "\n",
    "-\n",
    "* [к оглавлению](#разделы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все слова (в более общем случае - термы: слова и другие значимые элементы текста) которые встречаются в документах обрабатываемой коллекции, можно упорядочить. Если теперь для некоторого документа выписать по порядку веса всех термов, включая те, которых нет в этом документе, получится вектор, который и будет представлением данного документа в векторном пространстве.\n",
    "* Размерность этого вектора, как и размерность пространства, равна количеству различных термов во всей коллекции, и является одинаковой для всех документов.\n",
    "\n",
    "Записывая формально, документ $j$ описывается вектором:\n",
    "\n",
    "$$d_j = (w_{1j}, w_{2j},\\dotsc, w_{nj})$$\n",
    "\n",
    "где $d_j$ — векторное представление j-го документа, где $w_{ij}$ — вес i-го слова в j-м документе, n — общее количество различных термов во всех документах коллекции.\n",
    "\n",
    "Располагая таким представлением для всех документов, можно, например, находить расстояние между точками пространства и тем самым решать задачу подобия документов — чем ближе расположены точки, тем больше похожи соответствующие документы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Методы взвешивания термов__\n",
    "\n",
    "Для полного определения векторной модели необходимо указать, каким именно образом будет отыскиваться вес терма в документе. Существует несколько стандартных способов задания функции взвешивания:\n",
    "\n",
    "* __булевский вес__ — равен 1, если терм встречается в документе и 0 в противном случае;\n",
    "* __tf__ (term frequency, частота терма) — вес определяется как функция от количества вхождений терма в документе;\n",
    "* __tf-idf__ (term frequency — inverse document frequency, частота терма — обратная частота документа) — вес определяется как произведение функции от количества вхождений терма в документ и функции от величины, обратной количеству документов коллекции, в которых встречается этот терм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Косинусное сходство__\n",
    "\n",
    "Косинусное сходство — это мера сходства между двумя векторами предгильбертового пространства, которая используется для измерения косинуса угла между ними.\n",
    "\n",
    "Если даны два вектора признаков, A и B, то косинусное сходство, cos(θ), может быть представлено используя скалярное произведение и норму:\n",
    "\n",
    "\n",
    "$$\\text{similarity} = \\cos(\\theta) = {A \\cdot B \\over \\|A\\| \\|B\\|} = \\frac{ \\sum\\limits_{i=1}^{n}{A_i \\times B_i} }{ \\sqrt{\\sum\\limits_{i=1}^{n}{(A_i)^2}} \\times \\sqrt{\\sum\\limits_{i=1}^{n}{(B_i)^2}} }$$\n",
    "\n",
    "косинусное сходство двух документов изменяется в диапазоне от 0 до 1, поскольку частота терма (например, веса tf-idf) не может быть отрицательной. Угол между двумя векторами частоты терма не может быть больше, чем 90°.\n",
    "\n",
    "Одна из причин популярности косинуснуго сходства состоит в том, что __оно эффективно в качестве оценочной меры, особенно для разреженных векторов__, так как необходимо учитывать только ненулевые измерения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример 1: Тривиальный пример с векторизацией на основе подсчета слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools as it\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import nltk, string\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, TfidfVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# корпус текстов:\n",
    "corpus = ['This is the first document.',\n",
    "          'This document is the second document.',\n",
    "          'And this is the third one.',\n",
    "          'Is this the first document?']\n",
    "\n",
    "# создание векторизатора:\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# векторизуем корпус:\n",
    "corpus_cv = cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alpha\\.conda\\envs\\teach_e2\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# рассмотренные токены:\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_ar = corpus_cv.toarray()\n",
    "cv_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.23606798, 2.82842712, 2.44948974, 2.23606798])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm(cv_ar, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нормализация:\n",
    "ca_arn = cv_ar / norm(cv_ar, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.4472136 , 0.4472136 , 0.4472136 , 0.        ,\n",
       "        0.        , 0.4472136 , 0.        , 0.4472136 ],\n",
       "       [0.        , 0.70710678, 0.        , 0.35355339, 0.        ,\n",
       "        0.35355339, 0.35355339, 0.        , 0.35355339],\n",
       "       [0.40824829, 0.        , 0.        , 0.40824829, 0.40824829,\n",
       "        0.        , 0.40824829, 0.40824829, 0.40824829],\n",
       "       [0.        , 0.4472136 , 0.4472136 , 0.4472136 , 0.        ,\n",
       "        0.        , 0.4472136 , 0.        , 0.4472136 ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.79056942, 0.54772256, 1.        ],\n",
       "       [0.79056942, 1.        , 0.4330127 , 0.79056942],\n",
       "       [0.54772256, 0.4330127 , 1.        , 0.54772256],\n",
       "       [1.        , 0.79056942, 0.54772256, 1.        ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca_arn @ ca_arn.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание векторизатора:\n",
    "tv = TfidfVectorizer()\n",
    "\n",
    "# векторизуем корпус:\n",
    "corpus_tv = tv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# рассмотренные токены:\n",
    "tv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524],\n",
       "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tv.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.64692568, 0.30777187, 1.        ],\n",
       "       [0.64692568, 1.        , 0.22523955, 0.64692568],\n",
       "       [0.30777187, 0.22523955, 1.        , 0.30777187],\n",
       "       [1.        , 0.64692568, 0.30777187, 1.        ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_similarity = corpus_tv * corpus_tv.T \n",
    "pairwise_similarity.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример 2: Векторизация данных реального новостного потока\n",
    "\n",
    "* Источник данных: https://webhose.io/free-datasets/russian-news-articles/\n",
    "* альтернатива: https://github.com/RossiyaSegodnya/ria_news_dataset\n",
    "\n",
    "Этап 1: загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['news_0000001.json',\n",
       "  'news_0000002.json',\n",
       "  'news_0000003.json',\n",
       "  'news_0000004.json',\n",
       "  'news_0000005.json'],\n",
       " ['news_0000995.json',\n",
       "  'news_0000996.json',\n",
       "  'news_0000997.json',\n",
       "  'news_0000998.json',\n",
       "  'news_0000999.json'],\n",
       " 999)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получение имен всех файлов, находящихся по определенному пути:\n",
    "news_path = './news'\n",
    "news_files = [f for f in listdir(news_path) if isfile(join(news_path, f))]\n",
    "news_files[:5], news_files[-5:], len(news_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'organizations': [],\n",
       " 'uuid': '99bbd8fc99f9458417204a7107d21a0e03272d60',\n",
       " 'thread': {'social': {'gplus': {'shares': 0},\n",
       "   'pinterest': {'shares': 0},\n",
       "   'vk': {'shares': 0},\n",
       "   'linkedin': {'shares': 0},\n",
       "   'facebook': {'likes': 1, 'shares': 1, 'comments': 0},\n",
       "   'stumbledupon': {'shares': 0}},\n",
       "  'site_full': 'www.newsru.com',\n",
       "  'main_image': 'http://image.newsru.com/v2/02/2016/10//.jpg',\n",
       "  'site_section': 'http://feeds.newsru.com/com/www/news/main',\n",
       "  'section_title': 'NEWSru.com :: Важные новости',\n",
       "  'url': 'http://www.newsru.com/world/02oct2016/gulens.html',\n",
       "  'country': 'US',\n",
       "  'domain_rank': 3073,\n",
       "  'title': 'В Турции задержали очередного родственника Фетхуллаха Гюлена - его брата',\n",
       "  'performance_score': 0,\n",
       "  'site': 'newsru.com',\n",
       "  'participants_count': 0,\n",
       "  'title_full': 'В Турции задержали очередного родственника Фетхуллаха Гюлена - его брата',\n",
       "  'spam_score': 0.0,\n",
       "  'site_type': 'news',\n",
       "  'published': '2016-10-02T21:53:00.000+03:00',\n",
       "  'replies_count': 0,\n",
       "  'uuid': '99bbd8fc99f9458417204a7107d21a0e03272d60'},\n",
       " 'author': '',\n",
       " 'url': 'http://www.newsru.com/world/02oct2016/gulens.html',\n",
       " 'ord_in_thread': 0,\n",
       " 'title': 'В Турции задержали очередного родственника Фетхуллаха Гюлена - его брата',\n",
       " 'locations': [],\n",
       " 'entities': {'persons': [], 'locations': [], 'organizations': []},\n",
       " 'highlightText': '',\n",
       " 'language': 'russian',\n",
       " 'persons': [],\n",
       " 'text': 'В Турции задержали очередного родственника Фетхуллаха Гюлена - его брата   16:53   16:53 \\nТурецкая полиция задержала в городе Измир на западе страны брата оппозиционного исламского проповедника Фетхуллаха Гюлена Ктубеттина. Живущего в США проповедника Анкара считает вдохновителем попытки провалившегося переворота. Кутбеттин Гюлен разыскивался по обвинению в причастности к деятельности организации, возглавляемой его братом. Его доставили на допрос в Управление безопасности и, вероятно, вскоре предъявят обвинение. Операцию по задержанию провела полиция Измира на основе оперативных данных о том, что подозреваемый скрывается в доме своего родственника в районе Газиемир, передает РИА \"Новости\" . ТАСС напоминает, что 23 сентября власти Турции задержали племянницу Гюлена Эмине. Задержание прошло в уезде Эрдемит западной провинции Балыкесир. Выяснилось, что она значительную часть телефонных разговоров вела с одним абонентом в США. Кроме того, у нее изъято большое количество фотографий и книг Гюлена. В августе полиция задержала племянника Гюлена Кемаля Гюлена, телеведущего и адвоката. Он был задержан в одной из деревень в провинции Кастамону, где скрывался с середины июля после провала заговора. Еще раньше был задержан другой племянник проповедника Адбуллах Коруджук. В ночь на 16 июля в Турции группа мятежников совершила попытку военного переворота. Основное противостояние развернулось в Анкаре и Стамбуле. Погибли более 240 турецких граждан, более 2 тысяч человек получили ранения, мятеж был подавлен. Власти Турции обвинили Гюлена в причастности к попытке переворота и потребовали от США его экстрадиции. Сам Гюлен осудил мятеж и заявил о своей непричастности. По обвинению в причастности к организации Гюлена в Турции после мятежа были арестованы около 32 тысяч человек.',\n",
       " 'external_links': [],\n",
       " 'published': '2016-10-02T21:53:00.000+03:00',\n",
       " 'crawled': '2016-10-02T17:00:29.521+03:00',\n",
       " 'highlightTitle': ''}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(join(news_path, news_files[0]), 'r', encoding='utf-8') as f:\n",
    "    news_js = json.load(f)\n",
    "    \n",
    "news_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'В Турции задержали очередного родственника Фетхуллаха Гюлена - его брата   16:53   16:53 \\nТурецкая полиция задержала в городе Измир на западе страны брата оппозиционного исламского проповедника Фетхуллаха Гюлена Ктубеттина. Живущего в США проповедника Анкара считает вдохновителем попытки провалившегося переворота. Кутбеттин Гюлен разыскивался по обвинению в причастности к деятельности организации, возглавляемой его братом. Его доставили на допрос в Управление безопасности и, вероятно, вскоре предъявят обвинение. Операцию по задержанию провела полиция Измира на основе оперативных данных о том, что подозреваемый скрывается в доме своего родственника в районе Газиемир, передает РИА \"Новости\" . ТАСС напоминает, что 23 сентября власти Турции задержали племянницу Гюлена Эмине. Задержание прошло в уезде Эрдемит западной провинции Балыкесир. Выяснилось, что она значительную часть телефонных разговоров вела с одним абонентом в США. Кроме того, у нее изъято большое количество фотографий и книг Гюлена. В августе полиция задержала племянника Гюлена Кемаля Гюлена, телеведущего и адвоката. Он был задержан в одной из деревень в провинции Кастамону, где скрывался с середины июля после провала заговора. Еще раньше был задержан другой племянник проповедника Адбуллах Коруджук. В ночь на 16 июля в Турции группа мятежников совершила попытку военного переворота. Основное противостояние развернулось в Анкаре и Стамбуле. Погибли более 240 турецких граждан, более 2 тысяч человек получили ранения, мятеж был подавлен. Власти Турции обвинили Гюлена в причастности к попытке переворота и потребовали от США его экстрадиции. Сам Гюлен осудил мятеж и заявил о своей непричастности. По обвинению в причастности к организации Гюлена в Турции после мятежа были арестованы около 32 тысяч человек.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_js['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Уланова: чтобы охарактеризовать Гамову, достаточно одного слова — великая   22:02. Волейбол Либеро «Динамо Казань» Екатерина Уланова после прощального матча Екатерины Гамовой поделилась эмоциями, связанными с уходом Гамовой из спорта. «Слёзы на глаза накатываются, и мурашки по коже. Грустно, хотя понимаешь, конечно, что все мы рано или поздно будем уходить из спорта. Я очень счастливый человек, потому что мне удалось поиграть с Катей и в сборной, и в клубе. Какими словами я охарактеризовала бы Гамову? Мне достаточно одного слова – великая. И в жизни, и в спорте. Почему у нас не получилось шоу? Не знаю, что ответить на этот вопрос. Не мы решали. Сколько ни пытались сделать шоу в женском волейболе, не получается. Может быть, женский характер не позволяет раскрепоститься и сыграть в своё удовольствие. Да, сегодня была борьба, игра. Просто мы ещё не умеем делать шоу, не готовы к этому», — приводит слова Улановой «Спорт Бизнес Online».',\n",
       " 999)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_texts_corpus = []\n",
    "for nf in news_files:\n",
    "    with open(join(news_path, nf), 'r', encoding='utf-8') as f:\n",
    "        news_texts_corpus.append(json.load(f)['text'])\n",
    "        \n",
    "news_texts_corpus[42], len(news_texts_corpus)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_texts_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этап 2: предподготовка: токенизация, очистка от стоп слов, лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools as it\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готовим свой токенизатор (с нормализацией) и список стоп-слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_regex = re.compile('^[а-яА-ЯёЁ]*$')\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def n_tokenizer(news_str):\n",
    "    return [morph.parse(t.text.lower())[0].normalized.word for t in tokenize(news_str) \n",
    "                   if w_regex.search(t.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'В Турции задержали очередного родственника Фетхуллаха Гюлена - его брата   16:53   16:53 \\nТурецкая полиция задержала в городе Измир на западе страны брата оппозиционного исламского проповедника Фетхуллаха Гюлена Ктубеттина. Живущего в США проповедника Анкара считает вдохновителем попытки провалившегося переворота. Кутбеттин Гюлен разыскивался по обвинению в причастности к деятельности организации, возглавляемой его братом. Его доставили на допрос в Управление безопасности и, вероятно, вскоре предъявят обвинение. Операцию по задержанию провела полиция Измира на основе оперативных данных о том, что подозреваемый скрывается в доме своего родственника в районе Газиемир, передает РИА \"Новости\" . ТАСС напоминает, что 23 сентября власти Турции задержали племянницу Гюлена Эмине. Задержание прошло в уезде Эрдемит западной провинции Балыкесир. Выяснилось, что она значительную часть телефонных разговоров вела с одним абонентом в США. Кроме того, у нее изъято большое количество фотографий и книг Гюлена. В августе полиция задержала племянника Гюлена Кемаля Гюлена, телеведущего и адвоката. Он был задержан в одной из деревень в провинции Кастамону, где скрывался с середины июля после провала заговора. Еще раньше был задержан другой племянник проповедника Адбуллах Коруджук. В ночь на 16 июля в Турции группа мятежников совершила попытку военного переворота. Основное противостояние развернулось в Анкаре и Стамбуле. Погибли более 240 турецких граждан, более 2 тысяч человек получили ранения, мятеж был подавлен. Власти Турции обвинили Гюлена в причастности к попытке переворота и потребовали от США его экстрадиции. Сам Гюлен осудил мятеж и заявил о своей непричастности. По обвинению в причастности к организации Гюлена в Турции после мятежа были арестованы около 32 тысяч человек.'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_texts_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['в',\n",
       " 'турция',\n",
       " 'задержать',\n",
       " 'очередной',\n",
       " 'родственник',\n",
       " 'фетхуллах',\n",
       " 'гюлен',\n",
       " 'он',\n",
       " 'брат',\n",
       " 'турецкий',\n",
       " 'полиция',\n",
       " 'задержать',\n",
       " 'в',\n",
       " 'город',\n",
       " 'измир',\n",
       " 'на',\n",
       " 'запад',\n",
       " 'страна',\n",
       " 'брат',\n",
       " 'оппозиционный',\n",
       " 'исламский',\n",
       " 'проповедник',\n",
       " 'фетхуллах',\n",
       " 'гюлен',\n",
       " 'ктубеттин',\n",
       " 'жить',\n",
       " 'в',\n",
       " 'сша',\n",
       " 'проповедник',\n",
       " 'анкара',\n",
       " 'считать',\n",
       " 'вдохновитель',\n",
       " 'попытка',\n",
       " 'провалиться',\n",
       " 'переворот',\n",
       " 'кутбеттин',\n",
       " 'гюлен',\n",
       " 'разыскиваться',\n",
       " 'по',\n",
       " 'обвинение',\n",
       " 'в',\n",
       " 'причастность',\n",
       " 'к',\n",
       " 'деятельность',\n",
       " 'организация',\n",
       " 'возглавлять',\n",
       " 'он',\n",
       " 'брат',\n",
       " 'он',\n",
       " 'доставить',\n",
       " 'на',\n",
       " 'допрос',\n",
       " 'в',\n",
       " 'управление',\n",
       " 'безопасность',\n",
       " 'и',\n",
       " 'вероятно',\n",
       " 'вскоре',\n",
       " 'предъявить',\n",
       " 'обвинение',\n",
       " 'операция',\n",
       " 'по',\n",
       " 'задержание',\n",
       " 'провести',\n",
       " 'полиция',\n",
       " 'измир',\n",
       " 'на',\n",
       " 'основа',\n",
       " 'оперативный',\n",
       " 'данные',\n",
       " 'о',\n",
       " 'тот',\n",
       " 'что',\n",
       " 'подозревать',\n",
       " 'скрываться',\n",
       " 'в',\n",
       " 'дом',\n",
       " 'свой',\n",
       " 'родственник',\n",
       " 'в',\n",
       " 'район',\n",
       " 'газиемиро',\n",
       " 'передавать',\n",
       " 'риа',\n",
       " 'новость',\n",
       " 'тасс',\n",
       " 'напоминать',\n",
       " 'что',\n",
       " 'сентябрь',\n",
       " 'власть',\n",
       " 'турция',\n",
       " 'задержать',\n",
       " 'племянница',\n",
       " 'гюлен',\n",
       " 'эмин',\n",
       " 'задержание',\n",
       " 'пройти',\n",
       " 'в',\n",
       " 'уезд',\n",
       " 'эрдеметь',\n",
       " 'западный',\n",
       " 'провинция',\n",
       " 'балыкесир',\n",
       " 'выясниться',\n",
       " 'что',\n",
       " 'она',\n",
       " 'значительный',\n",
       " 'часть',\n",
       " 'телефонный',\n",
       " 'разговор',\n",
       " 'вести',\n",
       " 'с',\n",
       " 'один',\n",
       " 'абонент',\n",
       " 'в',\n",
       " 'сша',\n",
       " 'кроме',\n",
       " 'тот',\n",
       " 'у',\n",
       " 'она',\n",
       " 'изъять',\n",
       " 'большой',\n",
       " 'количество',\n",
       " 'фотография',\n",
       " 'и',\n",
       " 'книга',\n",
       " 'гюлен',\n",
       " 'в',\n",
       " 'август',\n",
       " 'полиция',\n",
       " 'задержать',\n",
       " 'племянник',\n",
       " 'гюлен',\n",
       " 'кемаля',\n",
       " 'гюлен',\n",
       " 'телеведущий',\n",
       " 'и',\n",
       " 'адвокат',\n",
       " 'он',\n",
       " 'быть',\n",
       " 'задержать',\n",
       " 'в',\n",
       " 'один',\n",
       " 'из',\n",
       " 'деревня',\n",
       " 'в',\n",
       " 'провинция',\n",
       " 'кастамон',\n",
       " 'где',\n",
       " 'скрываться',\n",
       " 'с',\n",
       " 'середина',\n",
       " 'июль',\n",
       " 'после',\n",
       " 'провал',\n",
       " 'заговор',\n",
       " 'ещё',\n",
       " 'ранний',\n",
       " 'быть',\n",
       " 'задержать',\n",
       " 'другой',\n",
       " 'племянник',\n",
       " 'проповедник',\n",
       " 'адбуллах',\n",
       " 'коруджук',\n",
       " 'в',\n",
       " 'ночь',\n",
       " 'на',\n",
       " 'июль',\n",
       " 'в',\n",
       " 'турция',\n",
       " 'группа',\n",
       " 'мятежник',\n",
       " 'совершить',\n",
       " 'попытка',\n",
       " 'военный',\n",
       " 'переворот',\n",
       " 'основный',\n",
       " 'противостояние',\n",
       " 'развернуться',\n",
       " 'в',\n",
       " 'анкара',\n",
       " 'и',\n",
       " 'стамбул',\n",
       " 'погибнуть',\n",
       " 'более',\n",
       " 'турецкий',\n",
       " 'гражданин',\n",
       " 'более',\n",
       " 'тысяча',\n",
       " 'человек',\n",
       " 'получить',\n",
       " 'ранение',\n",
       " 'мятеж',\n",
       " 'быть',\n",
       " 'подавить',\n",
       " 'власть',\n",
       " 'турция',\n",
       " 'обвинить',\n",
       " 'гюлен',\n",
       " 'в',\n",
       " 'причастность',\n",
       " 'к',\n",
       " 'попытка',\n",
       " 'переворот',\n",
       " 'и',\n",
       " 'потребовать',\n",
       " 'от',\n",
       " 'сша',\n",
       " 'он',\n",
       " 'экстрадиция',\n",
       " 'сам',\n",
       " 'гюлен',\n",
       " 'осудить',\n",
       " 'мятеж',\n",
       " 'и',\n",
       " 'заявить',\n",
       " 'о',\n",
       " 'свой',\n",
       " 'непричастность',\n",
       " 'по',\n",
       " 'обвинение',\n",
       " 'в',\n",
       " 'причастность',\n",
       " 'к',\n",
       " 'организация',\n",
       " 'гюлен',\n",
       " 'в',\n",
       " 'турция',\n",
       " 'после',\n",
       " 'мятеж',\n",
       " 'быть',\n",
       " 'арестовать',\n",
       " 'около',\n",
       " 'тысяча',\n",
       " 'человек']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test:\n",
    "n_tokenizer(news_texts_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['и',\n",
       " 'в',\n",
       " 'во',\n",
       " 'не',\n",
       " 'что',\n",
       " 'он',\n",
       " 'на',\n",
       " 'я',\n",
       " 'с',\n",
       " 'со',\n",
       " 'как',\n",
       " 'а',\n",
       " 'то',\n",
       " 'все',\n",
       " 'она',\n",
       " 'так',\n",
       " 'его',\n",
       " 'но',\n",
       " 'да',\n",
       " 'ты',\n",
       " 'к',\n",
       " 'у',\n",
       " 'же',\n",
       " 'вы',\n",
       " 'за',\n",
       " 'бы',\n",
       " 'по',\n",
       " 'только',\n",
       " 'ее',\n",
       " 'мне',\n",
       " 'было',\n",
       " 'вот',\n",
       " 'от',\n",
       " 'меня',\n",
       " 'еще',\n",
       " 'нет',\n",
       " 'о',\n",
       " 'из',\n",
       " 'ему',\n",
       " 'теперь',\n",
       " 'когда',\n",
       " 'даже',\n",
       " 'ну',\n",
       " 'вдруг',\n",
       " 'ли',\n",
       " 'если',\n",
       " 'уже',\n",
       " 'или',\n",
       " 'ни',\n",
       " 'быть',\n",
       " 'был',\n",
       " 'него',\n",
       " 'до',\n",
       " 'вас',\n",
       " 'нибудь',\n",
       " 'опять',\n",
       " 'уж',\n",
       " 'вам',\n",
       " 'ведь',\n",
       " 'там',\n",
       " 'потом',\n",
       " 'себя',\n",
       " 'ничего',\n",
       " 'ей',\n",
       " 'может',\n",
       " 'они',\n",
       " 'тут',\n",
       " 'где',\n",
       " 'есть',\n",
       " 'надо',\n",
       " 'ней',\n",
       " 'для',\n",
       " 'мы',\n",
       " 'тебя',\n",
       " 'их',\n",
       " 'чем',\n",
       " 'была',\n",
       " 'сам',\n",
       " 'чтоб',\n",
       " 'без',\n",
       " 'будто',\n",
       " 'чего',\n",
       " 'раз',\n",
       " 'тоже',\n",
       " 'себе',\n",
       " 'под',\n",
       " 'будет',\n",
       " 'ж',\n",
       " 'тогда',\n",
       " 'кто',\n",
       " 'этот',\n",
       " 'того',\n",
       " 'потому',\n",
       " 'этого',\n",
       " 'какой',\n",
       " 'совсем',\n",
       " 'ним',\n",
       " 'здесь',\n",
       " 'этом',\n",
       " 'один',\n",
       " 'почти',\n",
       " 'мой',\n",
       " 'тем',\n",
       " 'чтобы',\n",
       " 'нее',\n",
       " 'сейчас',\n",
       " 'были',\n",
       " 'куда',\n",
       " 'зачем',\n",
       " 'всех',\n",
       " 'никогда',\n",
       " 'можно',\n",
       " 'при',\n",
       " 'наконец',\n",
       " 'два',\n",
       " 'об',\n",
       " 'другой',\n",
       " 'хоть',\n",
       " 'после',\n",
       " 'над',\n",
       " 'больше',\n",
       " 'тот',\n",
       " 'через',\n",
       " 'эти',\n",
       " 'нас',\n",
       " 'про',\n",
       " 'всего',\n",
       " 'них',\n",
       " 'какая',\n",
       " 'много',\n",
       " 'разве',\n",
       " 'три',\n",
       " 'эту',\n",
       " 'моя',\n",
       " 'впрочем',\n",
       " 'хорошо',\n",
       " 'свою',\n",
       " 'этой',\n",
       " 'перед',\n",
       " 'иногда',\n",
       " 'лучше',\n",
       " 'чуть',\n",
       " 'том',\n",
       " 'нельзя',\n",
       " 'такой',\n",
       " 'им',\n",
       " 'более',\n",
       " 'всегда',\n",
       " 'конечно',\n",
       " 'всю',\n",
       " 'между']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_stop_words = stopwords.words('russian')\n",
    "\n",
    "n_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['В Турции задержали очередного родственника Фетхуллаха Гюлена - его брата   16:53   16:53 \\nТурецкая полиция задержала в городе Измир на западе страны брата оппозиционного исламского проповедника Фетхуллаха Гюлена Ктубеттина. Живущего в США проповедника Анкара считает вдохновителем попытки провалившегося переворота. Кутбеттин Гюлен разыскивался по обвинению в причастности к деятельности организации, возглавляемой его братом. Его доставили на допрос в Управление безопасности и, вероятно, вскоре предъявят обвинение. Операцию по задержанию провела полиция Измира на основе оперативных данных о том, что подозреваемый скрывается в доме своего родственника в районе Газиемир, передает РИА \"Новости\" . ТАСС напоминает, что 23 сентября власти Турции задержали племянницу Гюлена Эмине. Задержание прошло в уезде Эрдемит западной провинции Балыкесир. Выяснилось, что она значительную часть телефонных разговоров вела с одним абонентом в США. Кроме того, у нее изъято большое количество фотографий и книг Гюлена. В августе полиция задержала племянника Гюлена Кемаля Гюлена, телеведущего и адвоката. Он был задержан в одной из деревень в провинции Кастамону, где скрывался с середины июля после провала заговора. Еще раньше был задержан другой племянник проповедника Адбуллах Коруджук. В ночь на 16 июля в Турции группа мятежников совершила попытку военного переворота. Основное противостояние развернулось в Анкаре и Стамбуле. Погибли более 240 турецких граждан, более 2 тысяч человек получили ранения, мятеж был подавлен. Власти Турции обвинили Гюлена в причастности к попытке переворота и потребовали от США его экстрадиции. Сам Гюлен осудил мятеж и заявил о своей непричастности. По обвинению в причастности к организации Гюлена в Турции после мятежа были арестованы около 32 тысяч человек.',\n",
       " 'Aizvērt karti Высокие потолки, нужен ремонт-всё подготовлено для капитального ремонта, окна на одну сторону но шума нет, газовое отопление-колонка Viessmann-выравненный платёж 68 euro в месяц, городские коммуникации, вода по счетчикам только за холодную, пластиковые окна, камины действующие, два сарая во дворе c занесением в земельную книгу (22, 77m2), земля в собственности. Pilsēta:',\n",
       " 'Теги Локомотив Руслан Пименов Юрий Семин Премьер-лига Россия Арсенал Тула Бывший нападающий «Локомотива» Руслан Пименов после матча 9-го тура премьер-лиги с «Арсеналом» (1:1) выразил мнение, что многие футболисты «железнодорожников» не отвечают требованиям главного тренера Юрия Семина. Футболист не стал конкретизировать. – Главный тренер дал указание футболистам подумать, как им играть лучше. Ожидаете какие-то меры со стороны Семина? — вопрос Пименову. – Команду нужно встряхнуть. Многие футболисты не отвечают требованиями Юрия Павловича. – Кто именно?']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_texts_corpus[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alpha\\.conda\\envs\\teach_e2\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['большой', 'весь', 'всё', 'ещё', 'мочь', 'нибыть', 'свой', 'хороший', 'это'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 54s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# создание векторизатора:\n",
    "# vectorizer = TfidfVectorizer(tokenizer=n_tokenizer, stop_words=n_stop_words)\n",
    "cv_news = CountVectorizer(tokenizer=n_tokenizer, stop_words=n_stop_words)\n",
    "\n",
    "# векторизуем корпус:\n",
    "news_corpus_cv = cv_news.fit_transform(news_texts_corpus[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['аба',\n",
       "  'абаев',\n",
       "  'абай',\n",
       "  'абашидзе',\n",
       "  'аббас',\n",
       "  'аббревиатура',\n",
       "  'абделазиз',\n",
       "  'абдувахоб',\n",
       "  'абелла',\n",
       "  'абель',\n",
       "  'абер',\n",
       "  'абзац',\n",
       "  'абзелиловский',\n",
       "  'аблязов',\n",
       "  'абметко',\n",
       "  'абонемент',\n",
       "  'абонент',\n",
       "  'аборт',\n",
       "  'абрам',\n",
       "  'абрамс'],\n",
       " ['ясир',\n",
       "  'ясли',\n",
       "  'ясно',\n",
       "  'ясность',\n",
       "  'ясный',\n",
       "  'ясса',\n",
       "  'ястреб',\n",
       "  'яуза',\n",
       "  'яундубулт',\n",
       "  'яффа',\n",
       "  'яхрома',\n",
       "  'яхта',\n",
       "  'яхтсменка',\n",
       "  'яценко',\n",
       "  'яценюк',\n",
       "  'ячейка',\n",
       "  'яшин',\n",
       "  'ёвамар',\n",
       "  'ёжик',\n",
       "  'ёмкость'],\n",
       " 17761)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_fn = cv_news.get_feature_names()\n",
    "news_fn[:20], news_fn[-20:], len(news_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64),\n",
       " 17761,\n",
       " (999, 17761))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_ar = news_corpus_cv.toarray()\n",
    "news_ar[0][:40], len(news_ar[0]), news_ar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0] 17761 170 10\n"
     ]
    }
   ],
   "source": [
    "print(news_ar[0,:], len(news_ar[0,:]), sum(news_ar[0,:]), max(news_ar[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'аба': 0,\n",
       " 'абаев': 0,\n",
       " 'абай': 0,\n",
       " 'абашидзе': 0,\n",
       " 'аббас': 0,\n",
       " 'аббревиатура': 0,\n",
       " 'абделазиз': 0,\n",
       " 'абдувахоб': 0,\n",
       " 'абелла': 0,\n",
       " 'абель': 0,\n",
       " 'абер': 0,\n",
       " 'абзац': 0,\n",
       " 'абзелиловский': 0,\n",
       " 'аблязов': 0,\n",
       " 'абметко': 0,\n",
       " 'абонемент': 0,\n",
       " 'абонент': 1,\n",
       " 'аборт': 0,\n",
       " 'абрам': 0,\n",
       " 'абрамс': 0,\n",
       " 'абсолютно': 0,\n",
       " 'абсолютный': 0,\n",
       " 'абстрактный': 0,\n",
       " 'абсурд': 0,\n",
       " 'абсурдистский': 0,\n",
       " 'абсурдность': 0,\n",
       " 'абукаров': 0,\n",
       " 'абхазия': 0,\n",
       " 'абызов': 0,\n",
       " 'абэ': 0,\n",
       " 'авак': 0,\n",
       " 'авакова': 0,\n",
       " 'авангард': 0,\n",
       " 'аванпроект': 0,\n",
       " 'авантюрист': 0,\n",
       " 'аварийность': 0,\n",
       " 'аварийный': 0,\n",
       " 'авария': 0,\n",
       " 'авастина': 0,\n",
       " 'аватар': 0,\n",
       " 'август': 1,\n",
       " 'августовский': 0,\n",
       " 'авдеевка': 0,\n",
       " 'авено': 0,\n",
       " 'аверин': 0,\n",
       " 'аверьянов': 0,\n",
       " 'аветисов': 0,\n",
       " 'аветисян': 0,\n",
       " 'авиабаза': 0,\n",
       " 'авиабилет': 0,\n",
       " 'авиагруппа': 0,\n",
       " 'авиакатастрофа': 0,\n",
       " 'авиакомпания': 0,\n",
       " 'авиалайнер': 0,\n",
       " 'авиалиния': 0,\n",
       " 'авианалёт': 0,\n",
       " 'авиаперевозчик': 0,\n",
       " 'авиаполк': 0,\n",
       " 'авиасообщение': 0,\n",
       " 'авиатор': 0,\n",
       " 'авиатранспорт': 0,\n",
       " 'авиаудар': 0,\n",
       " 'авиационный': 0,\n",
       " 'авиация': 0,\n",
       " 'авокадо': 0,\n",
       " 'аврамопулос': 0,\n",
       " 'австралиец': 0,\n",
       " 'австралийка': 0,\n",
       " 'австралийский': 0,\n",
       " 'австралия': 0,\n",
       " 'австриец': 0,\n",
       " 'австрийский': 0,\n",
       " 'австрия': 0,\n",
       " 'авто': 0,\n",
       " 'автоавария': 0,\n",
       " 'автобизнесревю': 0,\n",
       " 'автобиографичный': 0,\n",
       " 'автобиография': 0,\n",
       " 'автобренд': 0,\n",
       " 'автобус': 0,\n",
       " 'автобусный': 0,\n",
       " 'автоваз': 0,\n",
       " 'автовладелец': 0,\n",
       " 'автогонки': 0,\n",
       " 'автограф': 0,\n",
       " 'автодорога': 0,\n",
       " 'автодорожный': 0,\n",
       " 'автодору': 0,\n",
       " 'автодром': 0,\n",
       " 'автозавод': 0,\n",
       " 'автозаводский': 0,\n",
       " 'автозак': 0,\n",
       " 'автокран': 0,\n",
       " 'автокредитный': 0,\n",
       " 'автокредитование': 0,\n",
       " 'автомат': 0,\n",
       " 'автоматизированный': 0,\n",
       " 'автоматизировать': 0,\n",
       " 'автоматически': 0,\n",
       " 'автоматический': 0,\n",
       " 'автомобилизация': 0,\n",
       " 'автомобилист': 0,\n",
       " 'автомобилистка': 0,\n",
       " 'автомобиль': 0,\n",
       " 'автомобильный': 0,\n",
       " 'автоном': 0,\n",
       " 'автономия': 0,\n",
       " 'автономка': 0,\n",
       " 'автономный': 0,\n",
       " 'автономович': 0,\n",
       " 'автопарк': 0,\n",
       " 'автопатруль': 0,\n",
       " 'автопроизводитель': 0,\n",
       " 'автопром': 0,\n",
       " 'автор': 0,\n",
       " 'авторизация': 0,\n",
       " 'авторизовать': 0,\n",
       " 'авторизоваться': 0,\n",
       " 'авторитаризм': 0,\n",
       " 'авторитарный': 0,\n",
       " 'авторитет': 0,\n",
       " 'авторитетный': 0,\n",
       " 'авторский': 0,\n",
       " 'авторынок': 0,\n",
       " 'автосалон': 0,\n",
       " 'автоспеццентр': 0,\n",
       " 'автосреда': 0,\n",
       " 'автостат': 0,\n",
       " 'автостоянка': 0,\n",
       " 'автострада': 0,\n",
       " 'автострахование': 0,\n",
       " 'автотранспорт': 0,\n",
       " 'автотранспортный': 0,\n",
       " 'автотрасса': 0,\n",
       " 'автоугонщик': 0,\n",
       " 'агаев': 0,\n",
       " 'агат': 0,\n",
       " 'агент': 0,\n",
       " 'агентство': 0,\n",
       " 'агитационный': 0,\n",
       " 'агитировать': 0,\n",
       " 'агн': 0,\n",
       " 'агнешка': 0,\n",
       " 'агония': 0,\n",
       " 'агора': 0,\n",
       " 'аграрий': 0,\n",
       " 'аграрный': 0,\n",
       " 'агрегат': 0,\n",
       " 'агрессивно': 0,\n",
       " 'агрессивный': 0,\n",
       " 'агрессия': 0,\n",
       " 'агрессор': 0,\n",
       " 'агро': 0,\n",
       " 'агробио': 0,\n",
       " 'агрогриб': 0,\n",
       " 'агроинвест': 0,\n",
       " 'агропродукция': 0,\n",
       " 'агропромышленный': 0,\n",
       " 'агротехнология': 0,\n",
       " 'агрохимикат': 0,\n",
       " 'агрохозяйство': 0,\n",
       " 'агрохолдинг': 0,\n",
       " 'агс': 0,\n",
       " 'агутиный': 0,\n",
       " 'ад': 0,\n",
       " 'адамов': 0,\n",
       " 'адамчик': 0,\n",
       " 'адаптация': 0,\n",
       " 'адаптер': 0,\n",
       " 'адаптировать': 0,\n",
       " 'адаптироваться': 0,\n",
       " 'адашкевич': 0,\n",
       " 'адбуллах': 1,\n",
       " 'адвокат': 1,\n",
       " 'адвокатский': 0,\n",
       " 'адвокатура': 0,\n",
       " 'адекватно': 0,\n",
       " 'адекватный': 0,\n",
       " 'адели': 0,\n",
       " 'адлерский': 0,\n",
       " 'административный': 0,\n",
       " 'администратор': 0,\n",
       " 'администрация': 0,\n",
       " 'администрирование': 0,\n",
       " 'админресурс': 0,\n",
       " 'адмирал': 0,\n",
       " 'адмиралтейский': 0,\n",
       " 'адмиро': 0,\n",
       " 'адольф': 0,\n",
       " 'адрес': 0,\n",
       " 'адресат': 0,\n",
       " 'адресный': 0,\n",
       " 'адресовать': 0,\n",
       " 'адресоваться': 0,\n",
       " 'адыгея': 0,\n",
       " 'аестаран': 0,\n",
       " 'аж': 0,\n",
       " 'ажиотаж': 0,\n",
       " 'ажурный': 0,\n",
       " 'аз': 0,\n",
       " 'азад': 0,\n",
       " 'азаров': 0,\n",
       " 'азатутюн': 0,\n",
       " 'азербайджан': 0,\n",
       " 'азербайджанский': 0,\n",
       " 'азиатский': 0,\n",
       " 'азиза': 0,\n",
       " 'азимут': 0,\n",
       " 'азия': 0,\n",
       " 'азов': 0,\n",
       " 'азовский': 0,\n",
       " 'азорский': 0,\n",
       " 'азот': 0,\n",
       " 'азотный': 0,\n",
       " 'азс': 0,\n",
       " 'азур': 0,\n",
       " 'аист': 0,\n",
       " 'аиф': 0,\n",
       " 'аиша': 0,\n",
       " 'айдамир': 0,\n",
       " 'айдар': 0,\n",
       " 'айкурт': 0,\n",
       " 'айнтрахт': 0,\n",
       " 'айон': 0,\n",
       " 'айсберри': 0,\n",
       " 'айфон': 0,\n",
       " 'ак': 0,\n",
       " 'академик': 0,\n",
       " 'академический': 0,\n",
       " 'академия': 0,\n",
       " 'акакий': 0,\n",
       " 'акация': 0,\n",
       " 'акб': 0,\n",
       " 'акватория': 0,\n",
       " 'акентьев': 0,\n",
       " 'аким': 0,\n",
       " 'акимат': 0,\n",
       " 'акимов': 0,\n",
       " 'акинфеев': 0,\n",
       " 'акинфей': 0,\n",
       " 'аккаунт': 0,\n",
       " 'акклиматизационный': 0,\n",
       " 'аккомазо': 0,\n",
       " 'аккорд': 0,\n",
       " 'аккредитация': 0,\n",
       " 'аккреционный': 0,\n",
       " 'аккумулятор': 0,\n",
       " 'аккумуляторный': 0,\n",
       " 'аккуратничать': 0,\n",
       " 'аккуратно': 0,\n",
       " 'аккуратный': 0,\n",
       " 'акп': 0,\n",
       " 'акробат': 0,\n",
       " 'аксель': 0,\n",
       " 'аксёнов': 0,\n",
       " 'акт': 0,\n",
       " 'актив': 0,\n",
       " 'активизация': 0,\n",
       " 'активизировать': 0,\n",
       " 'активизироваться': 0,\n",
       " 'активировать': 0,\n",
       " 'активист': 0,\n",
       " 'активистка': 0,\n",
       " 'активно': 0,\n",
       " 'активность': 0,\n",
       " 'активный': 0,\n",
       " 'актовый': 0,\n",
       " 'актриса': 0,\n",
       " 'актуально': 0,\n",
       " 'актуальный': 0,\n",
       " 'актёр': 0,\n",
       " 'актёрский': 0,\n",
       " 'акула': 0,\n",
       " 'акцент': 0,\n",
       " 'акцентировать': 0,\n",
       " 'акцепт': 0,\n",
       " 'акцептовать': 0,\n",
       " 'акциз': 0,\n",
       " 'акционер': 0,\n",
       " 'акционерный': 0,\n",
       " 'акция': 0,\n",
       " 'ала': 0,\n",
       " 'алаеддин': 0,\n",
       " 'аламяэ': 0,\n",
       " 'алармистский': 0,\n",
       " 'алгоритм': 0,\n",
       " 'але': 0,\n",
       " 'алевтина': 0,\n",
       " 'алейкума': 0,\n",
       " 'алекпер': 0,\n",
       " 'алекс': 0,\n",
       " 'александер': 0,\n",
       " 'александр': 0,\n",
       " 'александринский': 0,\n",
       " 'александров': 0,\n",
       " 'александрович': 0,\n",
       " 'александровск': 0,\n",
       " 'алексеев': 0,\n",
       " 'алексеевич': 0,\n",
       " 'алексей': 0,\n",
       " 'алексис': 0,\n",
       " 'ален': 0,\n",
       " 'алеппо': 0,\n",
       " 'алесь': 0,\n",
       " 'алжир': 0,\n",
       " 'алжирский': 0,\n",
       " 'алиев': 0,\n",
       " 'алик': 0,\n",
       " 'алина': 0,\n",
       " 'алисия': 0,\n",
       " 'алкаш': 0,\n",
       " 'алкашка': 0,\n",
       " 'алкмар': 0,\n",
       " 'алкоголизм': 0,\n",
       " 'алкоголик': 0,\n",
       " 'алкоголь': 0,\n",
       " 'алкогольный': 0,\n",
       " 'алла': 0,\n",
       " 'аллан': 0,\n",
       " 'аллар': 0,\n",
       " 'аллард': 0,\n",
       " 'аллегория': 0,\n",
       " 'аллегри': 0,\n",
       " 'аллергик': 0,\n",
       " 'аллергия': 0,\n",
       " 'аллея': 0,\n",
       " 'алли': 0,\n",
       " 'аллохол': 0,\n",
       " 'алмазбек': 0,\n",
       " 'алматы': 0,\n",
       " 'алмахать': 0,\n",
       " 'алонсо': 0,\n",
       " 'алоэ': 0,\n",
       " 'алсу': 0,\n",
       " 'алтай': 0,\n",
       " 'алтайский': 0,\n",
       " 'алушта': 0,\n",
       " 'алуштинский': 0,\n",
       " 'алфавит': 0,\n",
       " 'алхас': 0,\n",
       " 'аль': 0,\n",
       " 'альбер': 0,\n",
       " 'альберт': 0,\n",
       " 'альбом': 0,\n",
       " 'альварес': 0,\n",
       " 'альдегид': 0,\n",
       " 'алькасера': 0,\n",
       " 'альмадовар': 0,\n",
       " 'альпари': 0,\n",
       " 'альпийский': 0,\n",
       " 'альпы': 0,\n",
       " 'альт': 0,\n",
       " 'альтернатива': 0,\n",
       " 'альтернативный': 0,\n",
       " 'альтовый': 0,\n",
       " 'альтруист': 0,\n",
       " 'альфастрахование': 0,\n",
       " 'альфонсо': 0,\n",
       " 'альфред': 0,\n",
       " 'альфредо': 0,\n",
       " 'альцгеймер': 0,\n",
       " 'альянс': 0,\n",
       " 'алюминиевый': 0,\n",
       " 'алюминий': 0,\n",
       " 'алёна': 0,\n",
       " 'алёнка': 0,\n",
       " 'алёша': 0,\n",
       " 'аманда': 0,\n",
       " 'амбассадор': 0,\n",
       " 'амбициозный': 0,\n",
       " 'амброксол': 0,\n",
       " 'америка': 0,\n",
       " 'американец': 0,\n",
       " 'американка': 0,\n",
       " 'американофоб': 0,\n",
       " 'американский': 0,\n",
       " 'ами': 0,\n",
       " 'амиль': 0,\n",
       " 'амир': 0,\n",
       " 'амиранашвили': 0,\n",
       " 'амкара': 0,\n",
       " 'амман': 0,\n",
       " 'амнистировать': 0,\n",
       " 'амнистия': 0,\n",
       " 'амортизатор': 0,\n",
       " 'амплуа': 0,\n",
       " 'ампёрка': 0,\n",
       " 'амстердам': 0,\n",
       " 'амур': 0,\n",
       " 'амурский': 0,\n",
       " 'амурчан': 0,\n",
       " 'амфитеатр': 0,\n",
       " 'амхара': 0,\n",
       " 'ана': 0,\n",
       " 'анаболический': 0,\n",
       " 'анадырь': 0,\n",
       " 'анаклия': 0,\n",
       " 'анализ': 0,\n",
       " 'анализировать': 0,\n",
       " 'аналитик': 0,\n",
       " 'аналитика': 0,\n",
       " 'аналитический': 0,\n",
       " 'аналог': 0,\n",
       " 'аналогичный': 0,\n",
       " 'аналогия': 0,\n",
       " 'ананд': 0,\n",
       " 'ананидзе': 0,\n",
       " 'анар': 0,\n",
       " 'анастасия': 0,\n",
       " 'анат': 0,\n",
       " 'анатолиевич': 0,\n",
       " 'анатолий': 0,\n",
       " 'анатомия': 0,\n",
       " 'анащенко': 0,\n",
       " 'анвар': 0,\n",
       " 'ангара': 0,\n",
       " 'ангел': 0,\n",
       " 'ангела': 0,\n",
       " 'ангелика': 0,\n",
       " 'ангелина': 0,\n",
       " 'английский': 0,\n",
       " 'англичанин': 0,\n",
       " 'англия': 0,\n",
       " 'англоязычный': 0,\n",
       " 'ангола': 0,\n",
       " 'андалусие': 0,\n",
       " 'андерс': 0,\n",
       " 'анджей': 0,\n",
       " 'анджелина': 0,\n",
       " 'анджело': 0,\n",
       " 'андраник': 0,\n",
       " 'андре': 0,\n",
       " 'андреа': 0,\n",
       " 'андреас': 0,\n",
       " 'андреевич': 0,\n",
       " 'андрей': 0,\n",
       " 'андриан': 0,\n",
       " 'андрис': 0,\n",
       " 'анды': 0,\n",
       " 'аневризм': 0,\n",
       " 'анекдот': 0,\n",
       " 'анета': 0,\n",
       " 'анжелика': 0,\n",
       " 'анжи': 0,\n",
       " 'анзор': 0,\n",
       " 'ани': 0,\n",
       " 'аниш': 0,\n",
       " 'анкара': 2,\n",
       " 'анклав': 0,\n",
       " 'анна': 0,\n",
       " 'аннабель': 0,\n",
       " 'анне': 0,\n",
       " 'аннексия': 0,\n",
       " 'аннотация': 0,\n",
       " 'аннулировать': 0,\n",
       " 'ано': 0,\n",
       " 'анойкин': 0,\n",
       " 'аномалия': 0,\n",
       " 'аномально': 0,\n",
       " 'анонимность': 0,\n",
       " 'анонимный': 0,\n",
       " 'анонс': 0,\n",
       " 'анонсировать': 0,\n",
       " 'ансамбль': 0,\n",
       " 'анталья': 0,\n",
       " 'антарктида': 0,\n",
       " 'антарктика': 0,\n",
       " 'антиаборт': 0,\n",
       " 'антибиотик': 0,\n",
       " 'антигосударственный': 0,\n",
       " 'антидепрессант': 0,\n",
       " 'антидопинговый': 0,\n",
       " 'антикварный': 0,\n",
       " 'антикоррупционный': 0,\n",
       " 'антикризисный': 0,\n",
       " 'антимигрантский': 0,\n",
       " 'антиммигрантский': 0,\n",
       " 'антиммиграционный': 0,\n",
       " 'антимонопольный': 0,\n",
       " 'антинародный': 0,\n",
       " 'антипиратский': 0,\n",
       " 'антиреклама': 0,\n",
       " 'антисемитский': 0,\n",
       " 'антитеррористический': 0,\n",
       " 'антиукраинский': 0,\n",
       " 'антиутопия': 0,\n",
       " 'антихрист': 0,\n",
       " 'античный': 0,\n",
       " 'антон': 0,\n",
       " 'антонио': 0,\n",
       " 'антониу': 0,\n",
       " 'антрацит': 0,\n",
       " 'антрополог': 0,\n",
       " 'антропология': 0,\n",
       " 'антропометрия': 0,\n",
       " 'антти': 0,\n",
       " 'анхель': 0,\n",
       " 'анчелотти': 0,\n",
       " 'аншлаг': 0,\n",
       " 'аньковы': 0,\n",
       " 'аня': 0,\n",
       " 'ао': 0,\n",
       " 'ап': 0,\n",
       " 'апатия': 0,\n",
       " 'апеллировать': 0,\n",
       " 'апелляционный': 0,\n",
       " 'апелляция': 0,\n",
       " 'апельсин': 0,\n",
       " 'апк': 0,\n",
       " 'апл': 0,\n",
       " 'аплодисменты': 0,\n",
       " 'апокалипсис': 0,\n",
       " 'апостольский': 0,\n",
       " 'апофеоз': 0,\n",
       " 'аппарат': 0,\n",
       " 'аппаратный': 0,\n",
       " 'аппаратура': 0,\n",
       " 'аппетит': 0,\n",
       " 'апрель': 0,\n",
       " 'априори': 0,\n",
       " 'апробация': 0,\n",
       " 'аптекарский': 0,\n",
       " 'аптюшева': 0,\n",
       " 'арабкира': 0,\n",
       " 'арабский': 0,\n",
       " 'аравия': 0,\n",
       " 'арамидный': 0,\n",
       " 'арафат': 0,\n",
       " 'арбат': 0,\n",
       " 'арбатов': 0,\n",
       " 'арбитр': 0,\n",
       " 'арбитражный': 0,\n",
       " 'аргановое': 0,\n",
       " 'аргентина': 0,\n",
       " 'аргентинец': 0,\n",
       " 'аргентинский': 0,\n",
       " 'аргумент': 0,\n",
       " 'аргументация': 0,\n",
       " 'аргументированный': 0,\n",
       " 'аргументировать': 0,\n",
       " 'арена': 0,\n",
       " 'аренда': 0,\n",
       " 'арендатор': 0,\n",
       " 'арендный': 0,\n",
       " 'арендовать': 0,\n",
       " 'арендодатель': 0,\n",
       " 'арест': 0,\n",
       " 'арестант': 0,\n",
       " 'арестный': 0,\n",
       " 'арестовать': 1,\n",
       " 'арина': 0,\n",
       " 'арист': 0,\n",
       " 'аристократия': 0,\n",
       " 'ариша': 0,\n",
       " 'арка': 0,\n",
       " 'аркадий': 0,\n",
       " 'арктика': 0,\n",
       " 'арктический': 0,\n",
       " 'армагеддон': 0,\n",
       " 'армеец': 0,\n",
       " 'армейский': 0,\n",
       " 'армен': 0,\n",
       " 'армения': 0,\n",
       " 'армия': 0,\n",
       " 'армянский': 0,\n",
       " 'арнест': 0,\n",
       " 'арнольд': 0,\n",
       " 'аромат': 0,\n",
       " 'ароматный': 0,\n",
       " 'аронянин': 0,\n",
       " 'арочный': 0,\n",
       " 'арпеджион': 0,\n",
       " 'арпон': 0,\n",
       " 'арсен': 0,\n",
       " 'арсенал': 0,\n",
       " 'арсений': 0,\n",
       " 'арсеньев': 0,\n",
       " 'артема': 0,\n",
       " 'артериальный': 0,\n",
       " 'артерия': 0,\n",
       " 'артиллерийский': 0,\n",
       " 'артиллерист': 0,\n",
       " 'артиллерия': 0,\n",
       " 'артист': 0,\n",
       " 'артистка': 0,\n",
       " 'артобстрел': 0,\n",
       " 'артур': 0,\n",
       " 'артюхин': 0,\n",
       " 'артём': 0,\n",
       " 'артёмов': 0,\n",
       " 'арум': 0,\n",
       " 'архангельский': 0,\n",
       " 'архар': 0,\n",
       " 'археолог': 0,\n",
       " 'археология': 0,\n",
       " 'архив': 0,\n",
       " 'архивист': 0,\n",
       " 'архивный': 0,\n",
       " 'архиеретик': 0,\n",
       " 'архипелаг': 0,\n",
       " 'архитектор': 0,\n",
       " 'архитектура': 0,\n",
       " 'архитектурный': 0,\n",
       " 'архэнерго': 0,\n",
       " 'арчер': 0,\n",
       " 'арьен': 0,\n",
       " 'арьковы': 0,\n",
       " 'ас': 0,\n",
       " 'асад': 0,\n",
       " 'асеев': 0,\n",
       " 'асимметричный': 0,\n",
       " 'асимметрия': 0,\n",
       " 'аскар': 0,\n",
       " 'аскарово': 0,\n",
       " 'аслан': 0,\n",
       " 'аспект': 0,\n",
       " 'аспид': 0,\n",
       " 'аспирант': 0,\n",
       " 'асс': 0,\n",
       " 'ассад': 0,\n",
       " 'ассалам': 0,\n",
       " 'ассамблея': 0,\n",
       " 'ассамблеясын': 0,\n",
       " 'ассельборн': 0,\n",
       " 'ассигнование': 0,\n",
       " 'ассимиляция': 0,\n",
       " 'ассистент': 0,\n",
       " 'ассортимент': 0,\n",
       " 'ассортиментный': 0,\n",
       " 'ассоциация': 0,\n",
       " 'ассоциироваться': 0,\n",
       " 'ассошийэтед': 0,\n",
       " 'ассошиэйтед': 0,\n",
       " 'астан': 0,\n",
       " 'астана': 0,\n",
       " 'астероидный': 0,\n",
       " 'астроном': 0,\n",
       " 'астрофизик': 0,\n",
       " 'асунбула': 0,\n",
       " 'асфальт': 0,\n",
       " 'асфальтировать': 0,\n",
       " 'атака': 0,\n",
       " 'атаковать': 0,\n",
       " 'атамбаев': 0,\n",
       " 'атамекен': 0,\n",
       " 'атеросклероз': 0,\n",
       " 'атланта': 0,\n",
       " 'атлантика': 0,\n",
       " 'атлантический': 0,\n",
       " 'атласный': 0,\n",
       " 'атлетика': 0,\n",
       " 'атлетико': 0,\n",
       " 'атлетический': 0,\n",
       " 'атмосфера': 0,\n",
       " 'атмосферный': 0,\n",
       " 'ато': 0,\n",
       " 'атомный': 0,\n",
       " 'атошник': 0,\n",
       " 'атп': 0,\n",
       " 'атр': 0,\n",
       " 'атрибут': 0,\n",
       " 'атрощенко': 0,\n",
       " 'атташе': 0,\n",
       " 'аттила': 0,\n",
       " 'атут': 0,\n",
       " 'ауди': 0,\n",
       " 'аудио': 0,\n",
       " 'аудиозапись': 0,\n",
       " 'аудиоразъём': 0,\n",
       " 'аудит': 0,\n",
       " 'аудитория': 0,\n",
       " 'ауе': 0,\n",
       " 'аукцион': 0,\n",
       " 'аурелиано': 0,\n",
       " 'аут': 0,\n",
       " 'аутентичность': 0,\n",
       " 'аутоагрессия': 0,\n",
       " 'аутофагия': 0,\n",
       " 'аутсайдер': 0,\n",
       " 'аутспан': 0,\n",
       " 'афганистан': 0,\n",
       " 'афимолл': 0,\n",
       " 'афишировать': 0,\n",
       " 'афонино': 0,\n",
       " 'афонский': 0,\n",
       " 'африка': 0,\n",
       " 'африканец': 0,\n",
       " 'афроамериканец': 0,\n",
       " 'аффилировать': 0,\n",
       " 'аффэйрзнуть': 0,\n",
       " 'ахмад': 0,\n",
       " 'ахмадуллин': 0,\n",
       " 'ахматов': 0,\n",
       " 'ахмед': 0,\n",
       " 'ахмедов': 0,\n",
       " 'ахметель': 0,\n",
       " 'ахондроплазия': 0,\n",
       " 'ахрар': 0,\n",
       " 'ациклический': 0,\n",
       " 'ашукино': 0,\n",
       " 'аэробный': 0,\n",
       " 'аэродром': 0,\n",
       " 'аэрозольный': 0,\n",
       " 'аэрокосмический': 0,\n",
       " 'аэропорт': 0,\n",
       " 'аэрофлот': 0,\n",
       " 'аэрофотоаппарат': 0,\n",
       " 'аэс': 0,\n",
       " 'аякс': 0,\n",
       " 'б': 0,\n",
       " 'бабатунд': 0,\n",
       " 'бабель': 0,\n",
       " 'бабий': 0,\n",
       " 'бабло': 0,\n",
       " 'бабуркин': 0,\n",
       " 'бабушка': 0,\n",
       " 'бабушкин': 0,\n",
       " 'бавария': 0,\n",
       " 'баг': 0,\n",
       " 'багаж': 0,\n",
       " 'багамский': 0,\n",
       " 'багдад': 0,\n",
       " 'багдадский': 0,\n",
       " 'бадаламенти': 0,\n",
       " 'бадамшин': 0,\n",
       " 'бадер': 0,\n",
       " 'база': 0,\n",
       " 'базарный': 0,\n",
       " 'базироваться': 0,\n",
       " 'базовый': 0,\n",
       " 'базокоу': 0,\n",
       " 'байер': 0,\n",
       " 'байка': 0,\n",
       " 'байконур': 0,\n",
       " 'байт': 0,\n",
       " 'байтерек': 0,\n",
       " 'байымбетов': 0,\n",
       " 'бак': 0,\n",
       " 'бакалавриат': 0,\n",
       " 'бакстер': 0,\n",
       " 'бактерицидный': 0,\n",
       " 'бактерия': 0,\n",
       " 'баку': 0,\n",
       " 'балай': 0,\n",
       " 'балаклава': 0,\n",
       " 'балалайка': 0,\n",
       " 'баландин': 0,\n",
       " 'баланс': 0,\n",
       " 'балансирование': 0,\n",
       " 'балансировка': 0,\n",
       " 'балансодержатель': 0,\n",
       " 'баланюк': 0,\n",
       " 'балерина': 0,\n",
       " 'балет': 0,\n",
       " 'балкон': 0,\n",
       " 'балл': 0,\n",
       " 'баллада': 0,\n",
       " 'балластный': 0,\n",
       " 'баллистический': 0,\n",
       " 'баллон': 0,\n",
       " 'баллотироваться': 0,\n",
       " 'балльный': 0,\n",
       " 'балмера': 0,\n",
       " 'балотелли': 0,\n",
       " 'балтийск': 0,\n",
       " 'балтийский': 0,\n",
       " 'балтфлот': 0,\n",
       " 'балыкесир': 1,\n",
       " 'бальга': 0,\n",
       " 'бальда': 0,\n",
       " 'бан': 0,\n",
       " 'банально': 0,\n",
       " 'банальный': 0,\n",
       " 'бангкок': 0,\n",
       " 'банда': 0,\n",
       " 'бандераса': 0,\n",
       " 'бандит': 0,\n",
       " 'бандитский': 0,\n",
       " 'банить': 0,\n",
       " 'баниться': 0,\n",
       " 'банк': 0,\n",
       " 'банкир': 0,\n",
       " 'банкнот': 0,\n",
       " 'банковский': 0,\n",
       " 'банкрот': 0,\n",
       " 'банкротить': 0,\n",
       " 'банкротство': 0,\n",
       " 'баночка': 0,\n",
       " 'баня': 0,\n",
       " 'бар': 0,\n",
       " 'барабанщик': 0,\n",
       " 'барабаш': 0,\n",
       " 'барак': 0,\n",
       " 'барахло': 0,\n",
       " 'барбекю': 0,\n",
       " 'бардзалья': 0,\n",
       " 'барельеф': 0,\n",
       " 'баржа': 0,\n",
       " 'барка': 0,\n",
       " 'барнаул': 0,\n",
       " 'барраган': 0,\n",
       " 'баррель': 0,\n",
       " 'баррикада': 0,\n",
       " 'баррикадный': 0,\n",
       " 'барселона': 0,\n",
       " 'барыга': 0,\n",
       " 'барыс': 0,\n",
       " 'барьер': 0,\n",
       " 'бас': 0,\n",
       " 'баскаков': 0,\n",
       " 'баскетбол': 0,\n",
       " 'баскетболист': 0,\n",
       " 'баскетболистка': 0,\n",
       " 'баскетбольный': 0,\n",
       " 'баскин': 0,\n",
       " 'баснословный': 0,\n",
       " 'бассейн': 0,\n",
       " 'басурина': 0,\n",
       " 'баталин': 0,\n",
       " 'баталия': 0,\n",
       " 'батальон': 0,\n",
       " 'батальонный': 0,\n",
       " 'батарейка': 0,\n",
       " 'батарея': 0,\n",
       " 'батиашвили': 0,\n",
       " 'батрак': 0,\n",
       " 'баттон': 0,\n",
       " 'батькивщина': 0,\n",
       " 'батэ': 0,\n",
       " 'баумгартен': 0,\n",
       " 'бах': 0,\n",
       " 'бахаев': 0,\n",
       " 'бахра': 0,\n",
       " 'бачурский': 0,\n",
       " 'башар': 0,\n",
       " 'башенка': 0,\n",
       " 'башенный': 0,\n",
       " 'башкиравтодор': 0,\n",
       " 'башкирия': 0,\n",
       " 'башкортостан': 0,\n",
       " 'башнефть': 0,\n",
       " 'бгэу': 0,\n",
       " 'бд': 0,\n",
       " 'бдительность': 0,\n",
       " 'бебичка': 0,\n",
       " 'бег': 0,\n",
       " 'бегать': 0,\n",
       " 'беглец': 0,\n",
       " 'беглов': 0,\n",
       " 'беглый': 0,\n",
       " 'бегство': 0,\n",
       " 'бегун': 0,\n",
       " 'беда': 0,\n",
       " 'бедапечаль': 0,\n",
       " 'беджамов': 0,\n",
       " 'беднеть': 0,\n",
       " 'бедность': 0,\n",
       " 'бедный': 0,\n",
       " 'бедро': 0,\n",
       " 'бедствие': 0,\n",
       " 'бежать': 0,\n",
       " 'беженец': 0,\n",
       " 'беженский': 0,\n",
       " 'безалаберность': 0,\n",
       " 'безальтернативный': 0,\n",
       " 'безвизовый': 0,\n",
       " 'безвкусный': 0,\n",
       " 'безвозвратно': 0,\n",
       " 'безвозмездно': 0,\n",
       " 'безвыигрышный': 0,\n",
       " 'безвыходность': 0,\n",
       " 'безграмотность': 0,\n",
       " 'бездарный': 0,\n",
       " 'бездействие': 0,\n",
       " 'безделье': 0,\n",
       " 'бездна': 0,\n",
       " 'беззаконие': 0,\n",
       " 'беззащитный': 0,\n",
       " 'безмерно': 0,\n",
       " 'безналичный': 0,\n",
       " 'безопасность': 1,\n",
       " 'безопасный': 0,\n",
       " 'безоружный': 0,\n",
       " 'безосновательно': 0,\n",
       " 'безосновательный': 0,\n",
       " 'безответственный': 0,\n",
       " 'безотлагательно': 0,\n",
       " 'безотлагательный': 0,\n",
       " 'безошибочно': 0,\n",
       " 'безработица': 0,\n",
       " 'безработный': 0,\n",
       " 'безразличие': 0,\n",
       " 'безрезультатно': 0,\n",
       " 'безрецептурный': 0,\n",
       " 'безропотно': 0,\n",
       " 'безруков': 0,\n",
       " 'безудержный': 0,\n",
       " 'безумие': 0,\n",
       " 'безумно': 0,\n",
       " 'безупречный': 0,\n",
       " 'безусловно': 0,\n",
       " 'безусловный': 0,\n",
       " 'безуспешно': 0,\n",
       " 'бейджик': 0,\n",
       " 'бейль': 0,\n",
       " 'бейрак': 0,\n",
       " 'бейсбол': 0,\n",
       " 'бейсджампер': 0,\n",
       " 'бек': 0,\n",
       " 'бекежанов': 0,\n",
       " 'бекетов': 0,\n",
       " 'беким': 0,\n",
       " 'бекир': 0,\n",
       " 'беларусь': 0,\n",
       " 'белгород': 0,\n",
       " 'белгородский': 0,\n",
       " 'белен': 0,\n",
       " 'белиз': 0,\n",
       " 'белизский': 0,\n",
       " 'беликов': 0,\n",
       " 'белка': 0,\n",
       " 'белла': 0,\n",
       " 'беллухо': 0,\n",
       " 'белов': 0,\n",
       " 'белогорск': 0,\n",
       " 'белогорский': 0,\n",
       " 'белок': 0,\n",
       " 'белокочанный': 0,\n",
       " 'белокурый': 0,\n",
       " 'беломорск': 0,\n",
       " 'беломорский': 0,\n",
       " 'белоруска': 0,\n",
       " 'белоруссия': 0,\n",
       " 'белорусский': 0,\n",
       " 'белоснежок': 0,\n",
       " 'белоус': 0,\n",
       " 'белоусов': 0,\n",
       " 'белоярский': 0,\n",
       " 'белые': 0,\n",
       " 'белый': 0,\n",
       " 'бельгиец': 0,\n",
       " 'бельгийский': 0,\n",
       " 'бельгия': 0,\n",
       " 'бельё': 0,\n",
       " 'беляев': 0,\n",
       " 'беляков': 0,\n",
       " 'бемермана': 0,\n",
       " 'бен': 0,\n",
       " 'бена': 0,\n",
       " 'бенгальский': 0,\n",
       " 'бенджамин': 0,\n",
       " 'бенедисюк': 0,\n",
       " 'бенефициар': 0,\n",
       " 'бензин': 0,\n",
       " 'бензиновый': 0,\n",
       " 'бензовоз': 0,\n",
       " 'бензоколонка': 0,\n",
       " 'бента': 0,\n",
       " 'беньямина': 0,\n",
       " 'берг': 0,\n",
       " 'бердичев': 0,\n",
       " 'бердников': 0,\n",
       " 'берег': 0,\n",
       " 'береговой': 0,\n",
       " 'березуцкий': 0,\n",
       " 'беременеть': 0,\n",
       " 'беременная': 0,\n",
       " 'беременность': 0,\n",
       " 'беременный': 0,\n",
       " 'беречься': 0,\n",
       " 'бержерон': 0,\n",
       " 'беринг': 0,\n",
       " 'беркалов': 0,\n",
       " 'беркли': 0,\n",
       " 'беркут': 0,\n",
       " 'берлин': 0,\n",
       " 'бернардо': 0,\n",
       " 'берндт': 0,\n",
       " 'бернелла': 0,\n",
       " 'бернский': 0,\n",
       " 'бернуть': 0,\n",
       " 'берт': 0,\n",
       " 'берёза': 0,\n",
       " 'бес': 0,\n",
       " 'беседа': 0,\n",
       " 'бесик': 0,\n",
       " 'бесить': 0,\n",
       " 'бесконечный': 0,\n",
       " 'бесконтактный': 0,\n",
       " 'бескорыстный': 0,\n",
       " 'бескостный': 0,\n",
       " 'беслан': 0,\n",
       " 'беснёй': 0,\n",
       " 'беспардонно': 0,\n",
       " 'беспардонный': 0,\n",
       " 'беспартийный': 0,\n",
       " 'беспилотник': 0,\n",
       " 'беспилотный': 0,\n",
       " 'бесплатно': 0,\n",
       " 'бесплатный': 0,\n",
       " ...}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(news_fn, news_ar[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# news_ar = news_corpus_cv.toarray()\n",
    "news_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 17761)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_ar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_ar = corpus_cv.toarray()\n",
    "cv_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alpha\\AppData\\Local\\Temp\\ipykernel_2700\\3015992622.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  news_arn = news_ar / norm(news_ar, axis=1)[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "# нормализация:\n",
    "news_arn = news_ar / norm(news_ar, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.00919795, 0.        , ..., 0.06234117, 0.07357274,\n",
       "        0.02700276],\n",
       "       [0.00919795, 1.        , 0.01873172, ..., 0.        , 0.00888757,\n",
       "        0.        ],\n",
       "       [0.        , 0.01873172, 1.        , ..., 0.        , 0.04994384,\n",
       "        0.03142363],\n",
       "       ...,\n",
       "       [0.06234117, 0.        , 0.        , ..., 1.        , 0.08605355,\n",
       "        0.08967453],\n",
       "       [0.07357274, 0.00888757, 0.04994384, ..., 0.08605355, 1.        ,\n",
       "        0.1574812 ],\n",
       "       [0.02700276, 0.        , 0.03142363, ..., 0.08967453, 0.1574812 ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sim_mx = news_arn @ news_arn.T\n",
    "news_sim_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 октября 2016 02:45 SpaceX подозревает конкурентов во взрыве своей ракеты \\nАмериканская компания SpaceX подозревает, что ее конкурент – консорциум United Launch Alliance – причастен к аварии ракеты Falcon 9. Информация об этом появилась в газете The Washington Post . \\nКак уточняется, сотрудник SpaceX посетил объект ULA, расположенный на мысе Канаверал (штат Флорида) и попросил предоставить ему доступ на крышу одного из зданий, принадлежащих консорциуму. Здание располагается недалеко от пусковой площадки, где и произошла авария. В рамках расследования инцидента компания SpaceX хотела проверить одну особенность, вызвавшую подозрение. На видеозаписи взрыва специалисты компании обнаружили странную тень, а позже – белое пятно на здании ULA, расположенном неподалеку. \\nКак представитель SpaceX объяснил конкурентам, его компания прорабатывает все возможные версии аварии. Но в ULA ему не разрешили попасть на крышу того самого здания. Сотрудники консорциума вызвали специалиста из Военно-вооруженных сил США. Он осмотрел крышу и не нашел ничего подозрительного, что могло быть связано со взрывом ракеты Falcon 9. \\nПо данным газеты, сам Илон Маск , глава SpaceX, не отрицает версию о саботаже. ULA – совместное предприятие авиационного гиганта Boeing и Lockheed Martin. \\n1 сентября на космодроме, расположенном на мысе Канаверал, на площадке SpaceX взорвалась ракета Falcon 9 с израильским спутником связи Amos-6. В результате инцидента никто не пострадал, напоминает ТАСС .'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_idx = 41\n",
    "news_texts_corpus[n_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03815077, 0.        , 0.        , 0.04725417, 0.02177002,\n",
       "       0.        , 0.00817014, 0.01593402, 0.03005714, 0.0194717 ,\n",
       "       0.01467734, 0.01147381, 0.01314109, 0.03856908, 0.03442142,\n",
       "       0.01600563, 0.09652011, 0.02781671, 0.02829423, 0.1485761 ,\n",
       "       0.11553844, 0.01278379, 0.        , 0.0506523 , 0.02590476,\n",
       "       0.06227069, 0.0467695 , 0.02904462, 0.01529841, 0.02421883,\n",
       "       0.05632596, 0.03751621, 0.03389587, 0.05422932, 0.08814422,\n",
       "       0.05757427, 0.        , 0.00685012, 0.00746705, 0.00678329,\n",
       "       0.03387535, 1.        , 0.01703419, 0.54029124, 0.07769439,\n",
       "       0.        , 0.02819913, 0.04462646, 0.03569335, 0.        ,\n",
       "       0.04226541, 0.01807902, 0.04093638, 0.00628446, 0.05635924,\n",
       "       0.03382274, 0.0250073 , 0.03609808, 0.02808508,        nan,\n",
       "       0.04695043, 0.        , 0.00647619, 0.01435472, 0.02091267,\n",
       "       0.03391643, 0.05519707, 0.05812518, 0.07618379, 0.06582634,\n",
       "       0.04151379, 0.0413057 , 0.02980982, 0.04306417, 0.0372441 ,\n",
       "       0.04579358, 0.02909141, 0.        , 0.10539364, 0.04707222,\n",
       "       0.11473807, 0.01539373, 0.        , 0.01632751, 0.00874305,\n",
       "       0.        , 0.03941929, 0.04196363, 0.        , 0.03066255,\n",
       "       0.01839902, 0.0294082 , 0.04050357, 0.01996587, 0.01376857,\n",
       "       0.02726583, 0.02446224, 0.01004176, 0.02778129, 0.00495542,\n",
       "       0.01337322, 0.0465709 , 0.00521896, 0.03993173, 0.01709242,\n",
       "       0.08976008, 0.05597247, 0.07714245, 0.0355405 , 0.02150289,\n",
       "       0.01312781, 0.03954918, 0.02055036, 0.04383324, 0.04879291,\n",
       "       0.01383017, 0.01678969, 0.03729053, 0.07034468, 0.02688772,\n",
       "       0.03974643, 0.02602015, 0.08022586, 0.04193959, 0.0463087 ,\n",
       "       0.0498619 , 0.04359389, 0.00842623, 0.03359187, 0.03117151,\n",
       "       0.05204029, 0.06047417, 0.02996537, 0.07424586, 0.05145378,\n",
       "       0.02245406, 0.10139566, 0.03022593, 0.02477708, 0.03490969,\n",
       "       0.02607193, 0.04830333, 0.01600563, 0.06878783, 0.03447466,\n",
       "       0.04671339, 0.07125206, 0.03095993, 0.03459839, 0.02829423,\n",
       "       0.03223861, 0.00451004, 0.08087841, 0.01819705, 0.0349722 ,\n",
       "       0.08735348, 0.04354003, 0.05113518, 0.02300638, 0.0244919 ,\n",
       "       0.02130179, 0.05898408, 0.05362334, 0.06675621, 0.03268057,\n",
       "       0.05372326, 0.02008352, 0.00369568, 0.02810497, 0.04438011,\n",
       "       0.01502274, 0.02375304, 0.02335669, 0.02413105, 0.05825163,\n",
       "       0.02025179, 0.01579363, 0.00625844, 0.03714458, 0.09196386,\n",
       "       0.04954703, 0.03676564, 0.0112047 , 0.00733867, 0.01539373,\n",
       "       0.00451975, 0.10938162, 0.03991651, 0.0377164 , 0.05223106,\n",
       "       0.0464399 , 0.04237876, 0.        , 0.06798119, 0.1155533 ,\n",
       "       0.08538903, 0.07649204, 0.08863112, 0.06084905, 0.04306417,\n",
       "       0.03486905, 0.00879642, 0.09540273, 0.05188737, 0.04990738,\n",
       "       0.0638292 , 0.03525769, 0.02943507, 0.        , 0.04354003,\n",
       "       0.01116778, 0.02995719, 0.03203801, 0.0148255 , 0.02965889,\n",
       "       0.06536113, 0.06191987, 0.12968287, 0.        , 0.03494966,\n",
       "       0.01669684, 0.02829423, 0.02810497, 0.03535838, 0.07922385,\n",
       "       0.06539117, 0.04618118, 0.        , 0.04597484, 0.02869672,\n",
       "       0.01588681, 0.        , 0.05937277, 0.04354003, 0.01998923,\n",
       "       0.0574189 , 0.02571581, 0.01727695, 0.01579363, 0.        ,\n",
       "       0.02008352, 0.0032598 , 0.07670277, 0.02058222, 0.02803593,\n",
       "       0.02687349, 0.03638457, 0.03568269, 0.0859215 , 0.04513933,\n",
       "       0.05116128, 0.05456442, 0.04828185, 0.03704696, 0.07435876,\n",
       "       0.03653274, 0.02817026, 0.0531134 , 0.03903719, 0.03903022,\n",
       "       0.03040968, 0.02778129, 0.0451186 , 0.01370024, 0.        ,\n",
       "       0.02687861, 0.03252518, 0.05496202, 0.01643053, 0.08451077,\n",
       "       0.01309808, 0.03291317, 0.01807902, 0.02602015, 0.        ,\n",
       "       0.03158726, 0.02495183, 0.03059682, 0.03143255, 0.04683992,\n",
       "       0.07788678, 0.04116444, 0.10472907, 0.03296974, 0.01172058,\n",
       "       0.00410682, 0.01236454, 0.02950407, 0.01027518, 0.04510044,\n",
       "       0.        , 0.01925888, 0.        , 0.02894639, 0.04906406,\n",
       "       0.08879649, 0.01511297, 0.02239088, 0.05218962, 0.04997069,\n",
       "       0.032942  , 0.02263539, 0.01917569, 0.05511838, 0.0336141 ,\n",
       "       0.00691897, 0.        , 0.03650943, 0.01987322, 0.05458371,\n",
       "       0.04210379, 0.00896257, 0.00656391, 0.03498412, 0.06583611,\n",
       "       0.        , 0.06667401, 0.03581659, 0.03263838, 0.04038241,\n",
       "       0.02666272, 0.09333818, 0.00579761, 0.03007413, 0.04392126,\n",
       "       0.01251688, 0.        , 0.035952  , 0.00789682, 0.09190336,\n",
       "       0.03679805, 0.03903022, 0.05204029, 0.0924346 , 0.01734676,\n",
       "       0.05687743, 0.01207583, 0.03786163, 0.04381474, 0.02130179,\n",
       "       0.01520484, 0.03186804, 0.06351459, 0.0659771 , 0.04362738,\n",
       "       0.02294761, 0.01231498, 0.00911846, 0.03002184, 0.0724773 ,\n",
       "       0.04509485, 0.        , 0.01945614, 0.        , 0.05710936,\n",
       "       0.00590322, 0.03588681, 0.0496588 , 0.04310244, 0.07480783,\n",
       "       0.02327313, 0.02310533, 0.0207569 , 0.04555284, 0.04371525,\n",
       "       0.035952  , 0.03365735, 0.03469353, 0.04784908, 0.02928084,\n",
       "       0.03677634, 0.00698993, 0.03078745, 0.        , 0.02962524,\n",
       "       0.01912301, 0.02220809, 0.02729558, 0.05091618, 0.        ,\n",
       "       0.01713649, 0.05166509, 0.0241591 , 0.04236984, 0.02700238,\n",
       "       0.00789682, 0.03012528, 0.02472908, 0.05217852, 0.00751137,\n",
       "       0.03004548, 0.01229859, 0.04181331, 0.00998877, 0.02266945,\n",
       "       0.03796532, 0.01484703, 0.02233557, 0.06884284, 0.04364491,\n",
       "       0.01438952, 0.02400514, 0.1152297 , 0.03391643, 0.09523285,\n",
       "       0.02617643, 0.02810497, 0.04896986, 0.02165007, 0.03327644,\n",
       "       0.0327135 , 0.01569482, 0.03113535, 0.01643053, 0.02715198,\n",
       "       0.04177245, 0.02652771, 0.01549085, 0.02609634, 0.02462996,\n",
       "       0.01547997, 0.03339368, 0.14629103, 0.01115149, 0.01493411,\n",
       "       0.06734482, 0.02189198, 0.05084381, 0.05798438, 0.04724296,\n",
       "       0.03974643, 0.03142231, 0.04471474, 0.01966938, 0.03267867,\n",
       "       0.00742351, 0.08387918, 0.0251044 , 0.02065285, 0.02263539,\n",
       "       0.08062048, 0.0396649 , 0.05591945, 0.03291317, 0.05042116,\n",
       "       0.04687391, 0.11473807, 0.05818282, 0.02948058, 0.05251126,\n",
       "       0.        , 0.00751137, 0.03542998, 0.03865456, 0.03327644,\n",
       "       0.02114491, 0.06806811, 0.03447466, 0.11062817, 0.06157491,\n",
       "       0.05679244, 0.01097687, 0.06636323, 0.        , 0.03061782,\n",
       "       0.01847839, 0.03442142, 0.04671339, 0.01903509, 0.00702624,\n",
       "       0.05269682, 0.01607822, 0.05608028, 0.01885339, 0.00784537,\n",
       "       0.02772257, 0.0193789 , 0.03822612, 0.02375304, 0.02357441,\n",
       "       0.03695677, 0.01862205, 0.15473047, 0.03970051, 0.02867052,\n",
       "       0.02854528, 0.10501462, 0.01593402, 0.02370019, 0.02019121,\n",
       "       0.01811091, 0.0374733 , 0.03704696, 0.        , 0.08844433,\n",
       "       0.07051538, 0.12669442, 0.01059121, 0.1418499 , 0.01856553,\n",
       "       0.01762884, 0.07489114, 0.06875249, 0.00883254, 0.01622641,\n",
       "       0.05275158, 0.13662245, 0.03851777, 0.01226991, 0.11982535,\n",
       "       0.        , 0.00613301, 0.03513121, 0.04332872, 0.06663077,\n",
       "       0.03867595, 0.06071368, 0.05967041, 0.01001516, 0.03019675,\n",
       "       0.0259823 , 0.0619634 , 0.02387772, 0.05117048, 0.03496524,\n",
       "       0.03459483, 0.06227069, 0.01694794, 0.        , 0.        ,\n",
       "       0.03268057, 0.0909828 , 0.06610817, 0.01405249, 0.04403203,\n",
       "       0.08174243, 0.03974643, 0.        , 0.02319045, 0.04843765,\n",
       "       0.03864399, 0.0581367 , 0.05354716, 0.10873781, 0.03450957,\n",
       "       0.03426316, 0.05342989, 0.02433962, 0.01049843, 0.02795973,\n",
       "       0.07910376, 0.03291317, 0.0598475 , 0.06707986, 0.03113535,\n",
       "       0.05214386, 0.03872712, 0.05767917, 0.02864035, 0.04296053,\n",
       "       0.04769572, 0.04591631, 0.09572208, 0.0423805 , 0.01927985,\n",
       "       0.0294291 , 0.05143162, 0.0385597 , 0.06920384, 0.01405249,\n",
       "       0.05068451, 0.05328142, 0.08165866, 0.03395308, 0.02150289,\n",
       "       0.01966938, 0.02864035,        nan, 0.00911846, 0.02805597,\n",
       "       0.03751585, 0.00780047, 0.00370101, 0.04343248, 0.01887306,\n",
       "       0.0119941 , 0.03158726, 0.02369668, 0.02810497, 0.03389587,\n",
       "       0.04703789, 0.02828975, 0.02777625, 0.05216361, 0.00966364,\n",
       "       0.02839622, 0.03418484, 0.05620994, 0.01913963, 0.10094342,\n",
       "       0.01037845, 0.03168749, 0.0319146 , 0.01518428, 0.        ,\n",
       "       0.04497328, 0.0632435 , 0.02187279, 0.02738421, 0.01347243,\n",
       "       0.03868634, 0.01956979, 0.03923879, 0.08170142, 0.02073074,\n",
       "       0.01643053, 0.0931257 , 0.        , 0.07633514, 0.06203808,\n",
       "       0.02753714, 0.04545956, 0.02263539, 0.02099687, 0.00461006,\n",
       "       0.06264624, 0.06207718, 0.00817014, 0.04945816, 0.02561671,\n",
       "       0.02099687, 0.071904  , 0.03788398, 0.05218962, 0.01985025,\n",
       "       0.01078437, 0.04285763, 0.02199104, 0.03252518, 0.02760624,\n",
       "       0.01600563, 0.01909357, 0.02353611, 0.01397986, 0.03695677,\n",
       "       0.01669684, 0.00881442, 0.        , 0.02935469, 0.06678736,\n",
       "       0.02984716, 0.05158552, 0.03241609, 0.04559228, 0.03060067,\n",
       "       0.00902009, 0.06309987, 0.01823691, 0.03363193, 0.02602015,\n",
       "       0.03255345, 0.06411101, 0.01622641, 0.00968753, 0.00656391,\n",
       "       0.01429657, 0.011984  , 0.02446476, 0.02503376, 0.02668997,\n",
       "       0.0215661 , 0.04790594, 0.00932525, 0.07976463, 0.07869534,\n",
       "       0.        , 0.        , 0.0371019 , 0.06028984, 0.02468135,\n",
       "       0.1027414 , 0.01997754, 0.06419628, 0.04436944, 0.04261775,\n",
       "       0.        , 0.00811321, 0.08400482, 0.04647255, 0.01622641,\n",
       "       0.08126575, 0.01435472, 0.05591945, 0.02817026, 0.02118938,\n",
       "       0.        , 0.03113535, 0.04573669, 0.01420119, 0.00628446,\n",
       "       0.04050357, 0.00800282, 0.        , 0.        , 0.0309817 ,\n",
       "       0.0311065 , 0.00565037, 0.        , 0.01176328, 0.01683607,\n",
       "       0.02408998, 0.0186505 , 0.032343  , 0.02732875,        nan,\n",
       "       0.01869343, 0.04887051, 0.02336678, 0.03875012, 0.03430252,\n",
       "       0.01645659, 0.06511104, 0.02221893, 0.0207569 , 0.0572807 ,\n",
       "       0.01535114, 0.04050357, 0.03729053, 0.12073922, 0.01807902,\n",
       "       0.01216981, 0.01180645, 0.04543022, 0.04562446, 0.09892959,\n",
       "       0.00594712, 0.04906406, 0.0340555 , 0.06993047, 0.04443786,\n",
       "       0.05297523, 0.00594712, 0.01549085, 0.02649762, 0.03644621,\n",
       "       0.03407043, 0.01343675, 0.00615749, 0.04735656, 0.0267162 ,\n",
       "       0.04150727, 0.02172661, 0.01645659, 0.        , 0.03847597,\n",
       "       0.02625563, 0.02305029, 0.03885714, 0.15935503, 0.05148332,\n",
       "       0.06693339, 0.03022593, 0.07735882, 0.04585544, 0.0655925 ,\n",
       "       0.02579089, 0.01762884, 0.01539373, 0.01611489, 0.09157929,\n",
       "       0.05547292, 0.04455166, 0.05780487, 0.01015032, 0.0716763 ,\n",
       "       0.0389593 , 0.04205246, 0.02060382, 0.03827926, 0.03054407,\n",
       "       0.02440195, 0.01405249, 0.02452806, 0.        , 0.0242451 ,\n",
       "       0.01301007, 0.01301007, 0.01301007, 0.01645659, 0.02951612,\n",
       "       0.04237744, 0.        , 0.04481881, 0.03054407, 0.02740047,\n",
       "       0.01556767, 0.0380121 , 0.01467734, 0.        , 0.0708387 ,\n",
       "       0.05047802, 0.05620994, 0.03694494, 0.03469013, 0.02294761,\n",
       "       0.04300578, 0.03713107, 0.04398208, 0.05706037, 0.02398254,\n",
       "       0.01088501, 0.01324881, 0.04306417, 0.01200423, 0.05898359,\n",
       "       0.03307103, 0.08374439, 0.09845861, 0.02523901, 0.06760233,\n",
       "       0.04533333, 0.02700238, 0.03795463, 0.06024526, 0.03343304,\n",
       "       0.00874305, 0.        , 0.03182261, 0.01622641, 0.05519707,\n",
       "       0.02954396, 0.05412053, 0.01212255, 0.04481881, 0.05888384,\n",
       "       0.05977552, 0.0285955 , 0.04419633, 0.00376129, 0.06573218,\n",
       "       0.03422149, 0.0924346 , 0.04549263, 0.        , 0.08850771,\n",
       "       0.051766  , 0.05898359, 0.02227054, 0.09851391, 0.0083078 ,\n",
       "       0.01589857, 0.02360058, 0.01694794, 0.03691212,        nan,\n",
       "       0.04113397, 0.08784251, 0.01748035, 0.03503504, 0.08362662,\n",
       "       0.03933877, 0.09013643, 0.0463087 , 0.05632596, 0.05783955,\n",
       "       0.03116369, 0.07626571, 0.04530858, 0.        , 0.05374699,\n",
       "       0.0524964 , 0.02810497, 0.11596368, 0.1187192 , 0.04937696,\n",
       "       0.06138338, 0.09135291, 0.02624609, 0.03795858, 0.03733527,\n",
       "       0.04056603, 0.023968  , 0.04438011, 0.0362585 , 0.01261574,\n",
       "       0.18901668, 0.14459888, 0.04775545, 0.02587272, 0.05381692,\n",
       "       0.        , 0.10266446, 0.04226541, 0.        , 0.05535173,\n",
       "       0.025273  , 0.00719695, 0.13349861, 0.08376119, 0.03921646,\n",
       "       0.04313887, 0.03842433, 0.02025179, 0.14335297, 0.01579363,\n",
       "       0.02401352, 0.04887051, 0.03016095, 0.03070052, 0.02930146,\n",
       "       0.08204057, 0.        , 0.12430811, 0.00729733, 0.02810497,\n",
       "       0.06419628, 0.04823467, 0.02042535, 0.05214386, 0.00775771,\n",
       "       0.00729733, 0.02490647, 0.06736615, 0.02810497, 0.07189269,\n",
       "       0.03954102, 0.05745777, 0.01236454, 0.03484602, 0.05149819,\n",
       "       0.04522938, 0.        , 0.0368518 , 0.16666856, 0.04363711,\n",
       "       0.02920754, 0.09964958, 0.14685357, 0.0531134 , 0.09617833,\n",
       "       0.0638292 , 0.02227054, 0.04738089, 0.02753714, 0.00954678,\n",
       "       0.05184346, 0.04684162, 0.06505037, 0.01383793, 0.14153743,\n",
       "       0.04589523, 0.07129891, 0.02472908, 0.02323627, 0.08033408,\n",
       "       0.01301007, 0.02263539, 0.04359389, 0.04085071, 0.05519707,\n",
       "       0.01075145, 0.01766104, 0.02558524, 0.02986822, 0.05408804,\n",
       "       0.08325962, 0.06446321, 0.00372259, 0.        , 0.03158726,\n",
       "       0.04739336, 0.03818714, 0.02477351, 0.04063664, 0.02150289,\n",
       "       0.02107873, 0.0196194 , 0.10684937, 0.05508338, 0.018824  ,\n",
       "       0.12783794, 0.032942  , 0.02302771, 0.        , 0.01823691,\n",
       "       0.03650943, 0.02938782, 0.03339368, 0.05632596, 0.01324881,\n",
       "       0.02671495, 0.0396649 , 0.01484703, 0.01631159, 0.        ,\n",
       "       0.02904662, 0.09735848, 0.07707799, 0.04085251])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sim_mx[n_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sim_mx[n_idx, :].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sim_mx[n_idx, 59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 61,  77, 868, 493, 911, 968, 647, 326, 510, 843,  49, 192,  45,\n",
       "       753, 528, 315, 351, 529, 353,  85, 695, 702, 703, 893, 685, 450,\n",
       "       676, 707, 675, 931, 890, 463, 379, 373,  88,  82, 826, 791, 604,\n",
       "        22, 208, 274, 264, 798, 306, 617, 783, 292, 994, 290, 227, 218,\n",
       "         5, 537, 983,   2,  36,   1, 239, 231, 241, 167, 582, 967, 838,\n",
       "       285, 151, 185, 624,  99, 102, 706, 322, 355, 741, 735, 511, 747,\n",
       "       177,  53, 699,  62, 664, 312,  39,  37, 305, 371, 469, 896, 920,\n",
       "       913, 183, 435,  38, 451, 389, 919, 581, 474, 385, 328, 701, 686,\n",
       "         6, 627, 849, 127, 825,  84, 201, 646, 503, 311, 655, 578, 347,\n",
       "       672, 944, 594, 663, 393, 518,  97, 773, 288, 600, 548, 497, 960,\n",
       "       635, 810, 461, 423, 210, 182,  11, 284, 708, 731, 666, 585, 813,\n",
       "       336, 832, 730, 508, 391, 346, 927, 286, 325, 884,  21, 955, 786,\n",
       "       787, 785, 270, 110,  12, 811, 989, 100, 746, 609, 263,  94, 115,\n",
       "       948, 643, 533, 781, 569, 698, 665, 691,  63, 400,  10, 797, 213,\n",
       "       992, 396, 424, 170, 296, 603, 340,  28, 725, 184, 767,  81, 420,\n",
       "       742, 417, 795, 411, 176, 904, 238, 230, 850, 487,   7,  15, 142,\n",
       "       640, 471, 768, 689, 504, 662, 828, 993,  83, 413, 615, 268, 752,\n",
       "       788, 720, 645, 220, 116, 709, 527, 852,  42, 104, 380, 237, 334,\n",
       "       857, 766, 500, 961, 729,  51, 272, 490, 153, 984, 657,  90, 465,\n",
       "       499, 481, 711, 715, 979, 473, 584, 468, 641, 375, 598, 302, 291,\n",
       "       564, 476, 352,   9, 611, 976, 433, 575, 634, 308,  93, 681, 234,\n",
       "       240, 166, 489, 175, 902, 917, 112, 243, 777, 438, 614, 723, 362,\n",
       "        64, 623, 630, 975, 455, 694, 339, 160, 109, 974, 574, 670, 408,\n",
       "       751,   4, 607, 426, 637, 376, 722, 847, 941, 397, 297, 135, 301,\n",
       "       439, 622, 956, 394, 804, 345, 158, 982, 756, 361, 538, 953, 360,\n",
       "       172, 717, 642, 479, 851, 587, 488, 171, 478, 522, 881, 809, 401,\n",
       "       905, 710, 173, 382,  29, 784, 547, 780,  96, 667, 159, 782, 419,\n",
       "       679, 952, 387, 972, 138, 921, 276,  56, 668, 437, 818, 895, 962,\n",
       "       629, 236, 765, 888,  24, 520, 121, 273, 659, 140, 418, 405, 877,\n",
       "       755, 743, 416, 320, 669, 990, 749, 245, 265, 119, 821, 384, 414,\n",
       "        95, 377, 713, 608, 794, 943, 620, 639, 475, 592, 261,  98,  17,\n",
       "       549, 244, 579,  58, 406, 914, 588, 222, 871, 923, 168, 693, 256,\n",
       "        46, 591,  18, 149, 221, 595, 485, 836, 576, 558, 484, 229, 293,\n",
       "        27, 995,  76, 935, 369, 909, 648, 986,  91, 565, 207, 448, 287,\n",
       "       789, 830, 374, 214,  72, 650, 963, 211, 132, 348, 390,   8, 323,\n",
       "       386, 907, 519, 137, 761, 260, 779, 793, 277, 654, 464,  89, 908,\n",
       "       372, 147, 704, 705, 696, 412, 554, 865, 129, 431, 278, 275, 586,\n",
       "       969, 601, 827, 341, 602, 212, 150, 712, 652, 638, 266, 660, 318,\n",
       "       434, 164, 530, 410, 551, 271, 443, 300, 981, 283, 815, 454, 409,\n",
       "       987, 421, 824, 128, 304, 658, 366,  55,  40, 589,  32,  65, 403,\n",
       "       573, 737, 745, 596, 840, 545, 719, 466,  14, 144, 457, 544, 525,\n",
       "       148, 803, 367, 928, 200, 139, 219, 524, 154, 313, 858, 512, 206,\n",
       "       223, 452, 108, 247,  48, 317, 356, 327, 365,  57, 883, 246, 744,\n",
       "       985, 307, 255, 181, 370, 330, 932, 853, 802, 480, 644, 253, 492,\n",
       "       677, 806, 178,  74, 727, 117, 879, 491, 580,  31, 188, 337, 632,\n",
       "       822, 878, 395, 796,   0, 971, 477, 778, 901, 754, 507, 567,  13,\n",
       "       540, 453, 515, 610, 556, 718, 757, 775, 331, 259, 258, 899, 612,\n",
       "       860,  86, 925, 111, 991, 441, 483, 120, 430, 536, 187, 103, 319,\n",
       "       700,  92, 726, 880, 973, 958, 998,  52, 855, 281,  71, 750,  70,\n",
       "       415, 392, 123,  87, 776, 310,  50, 892, 383, 790, 191, 563, 684,\n",
       "       636, 559, 805, 199,  73, 812, 358, 900, 513, 583, 233, 156, 209,\n",
       "       126, 957, 344, 934, 399, 364, 338, 113, 324, 807, 534, 837, 683,\n",
       "       882, 169, 739, 771,  47, 432, 792, 833, 605, 350, 289, 262, 249,\n",
       "       930, 867, 820, 732, 621, 842, 363, 653, 733, 697,  75, 763, 950,\n",
       "       561, 228, 226, 862, 124, 190, 688, 101, 145, 467,  26, 279, 946,\n",
       "       445,  60, 590,  79, 429,   3, 748, 942, 970, 560, 887, 368, 671,\n",
       "       916, 252, 141, 539, 114, 716, 906, 407, 736, 294, 874, 628, 180,\n",
       "       357, 125, 204, 299, 444, 800,  23, 570, 427, 378, 157, 250, 523,\n",
       "       566, 134, 759, 929, 651, 381, 845, 945, 203, 332, 130, 918, 555,\n",
       "       593, 388, 633, 298, 189, 870, 449, 470, 505, 740, 257, 938, 571,\n",
       "       546, 542, 162, 165, 869, 889, 964, 831,  33, 251, 309, 267, 978,\n",
       "       303, 829,  66, 959, 894, 770, 692, 442, 106, 472, 597, 801,  30,\n",
       "       863, 988,  54, 460, 335, 808, 354, 724, 235, 926,  35, 557, 772,\n",
       "       864, 428,  67, 541, 447, 174, 834, 846, 814, 161, 232, 517, 835,\n",
       "       552, 823, 678, 131, 516, 198, 875, 459, 216, 521, 619, 626, 526,\n",
       "        25, 625, 656, 606, 342, 205, 940, 661, 682, 915, 966, 947, 721,\n",
       "       215, 225, 764, 839,  69, 314, 343, 532, 462, 514, 316, 163, 649,\n",
       "       760, 553, 425, 922, 819, 193, 456, 502, 143, 398, 568, 738, 118,\n",
       "       495, 799, 146, 951, 774, 924, 631, 349, 133, 254, 359, 501,  68,\n",
       "       866, 618, 196, 242, 997, 107, 762,  44, 280, 674, 550, 224, 673,\n",
       "       122, 954, 440, 152, 690, 572, 613, 535, 910, 965, 859, 816, 898,\n",
       "       436, 687, 269, 195, 248, 155, 856,  34, 494, 844, 197, 295, 105,\n",
       "       861, 531, 876, 769, 329, 179, 333, 841, 616, 321, 404, 202, 562,\n",
       "       939,  16, 996, 817, 848, 734, 936, 599, 136, 891, 680, 282, 486,\n",
       "        78, 977, 543, 186, 458,  80, 446, 402,  20, 194, 872, 873, 509,\n",
       "       728, 912, 496, 980, 217, 897, 506, 949, 498, 903, 886, 422, 937,\n",
       "        19, 482, 758, 933, 885,  43,  41,  59, 854, 577, 714], dtype=int64)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sim_mx[n_idx, :].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5402912369036817"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_sim_mx[n_idx, 43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'По предварительным данным, причиной взрыва могла стать утечка бытового газа. Инцидент произошел в городе Харбин. Также сообщается, что в результате взрыва пострадали несколько человек, их число уточняется. Фото: х'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_texts_corpus[885]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
